{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from utils_new import extract_PID_data, resample_PID_data, Throttle_Constraint, RPM_Constraint, Speed_Constraint, Remove_Outliers\n",
    "import os\n",
    "import json\n",
    "from operator import itemgetter\n",
    "import seaborn as sns\n",
    "#from scipy.stats import pearson\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial import distance\n",
    "import plotly.graph_objects as go\n",
    "#from datetime import  timezone\n",
    "import datetime\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import norm\n",
    "from scipy import signal\n",
    "import plotly.express as px\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define the URL for the API endpoint\n",
    "url = \"https://algo-internal-apis.intangles-aws-us-east-1.intangles.us/dtc/info\"\n",
    "\n",
    "# Define the dtcs parameter as a list of DTC IDs\n",
    "dtcs = [\"P0404\", \"P0195\", \"P02DD\"]  # Replace with actual DTC IDs\n",
    "\n",
    "# Construct the request body\n",
    "body = {\n",
    "    \"dtcs\": dtcs\n",
    "}\n",
    "\n",
    "# Send the POST request\n",
    "try:\n",
    "    response = requests.post(url, json=body)\n",
    "\n",
    "    # Check the response status\n",
    "    if response.status_code == 200:\n",
    "        print(\"Success:\", response.json())\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.json())\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define the URL for the API endpoint\n",
    "url = \"https://algo-internal-apis.intangles-aws-us-east-1.intangles.us/dtc/info\"\n",
    "\n",
    "# Define the dtcs parameter as a list of DTC IDs\n",
    "body = {\n",
    "    \"dtcs\": {\n",
    "        \"codes\": [\"P0404\", \"P0195\", \"P02DD\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Construct the request body\n",
    "body = {\n",
    "    \"dtcs\": dtcs\n",
    "}\n",
    "\n",
    "# Print the request body for debugging\n",
    "print(\"Request Body:\", body)\n",
    "\n",
    "# Send the POST request\n",
    "try:\n",
    "    response = requests.post(url, json=body)\n",
    "\n",
    "    # Check the response status\n",
    "    if response.status_code == 200:\n",
    "        print(\"Success:\", response.json())\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.json())\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://algo-internal-apis.intangles-aws-us-east-1.intangles.us/dtc/info/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_response = requests.post(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcs = [\" P0195 \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "headers = {\n",
    "                'Content-Type': 'application/json',\n",
    "            }\n",
    "vehicle_dtc_data =  {\"dtcs\": dtcs}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_response = requests.post(url, json=vehicle_dtc_data, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_PID_data(data, PROTOCOL,LABEL):\n",
    "    \n",
    "    if (PROTOCOL == 'SAE_avg'):\n",
    "\n",
    "        if LABEL == 'IMAP':\n",
    "            PID_TAG = 'spn_106_avg'\n",
    "        elif LABEL == 'ENGINE LOAD':\n",
    "            PID_TAG = 'spn_92_avg'\n",
    "        elif LABEL == 'ENGINE RPM':\n",
    "            PID_TAG = 'spn_190_avg'\n",
    "        elif LABEL == 'FUEL RATE':\n",
    "            PID_TAG = 'spn_183_avg'\n",
    "        elif LABEL == 'MAF':\n",
    "            PID_TAG = 'spn_132_avg'\n",
    "        elif LABEL == 'BOOST':\n",
    "            PID_TAG = 'spn_102_avg'\n",
    "        elif LABEL == 'BAROMETER':\n",
    "            PID_TAG = 'spn_108_avg'\n",
    "        elif LABEL == 'THROTTLE':\n",
    "            PID_TAG = 'spn_91_avg'\n",
    "        elif LABEL == 'ATGMF': # Eaxuast Gas Flow Rate\n",
    "            PID_TAG = 'spn_3236_avg'\n",
    "        elif LABEL == 'DPFDP': # DPF Diffrential Pressure (across DPF)\n",
    "            PID_TAG = 'spn_3251_avg'\n",
    "        elif LABEL == 'SCRT':   # SCR Catalyst Temperature Before Catalyst (DPF out)\n",
    "            PID_TAG = 'spn_4360_avg'\n",
    "        elif LABEL == 'SPEED': # Wheep based Vehicle Speed\n",
    "            PID_TAG = 'spn_84_avg'\n",
    "        elif LABEL == 'DPFINT':# DPF in Temperature Before DPF (DOC out)\n",
    "            PID_TAG = 'spn_3250_avg' #4766\n",
    "        elif LABEL == 'IS': #  regen inhibited\n",
    "            PID_TAG = 'spn_3703_avg'        \n",
    "        elif LABEL == 'FUEL USE': #  Total fuel used (high precision)\n",
    "            PID_TAG = 'spn_5054_avg'        \n",
    "        elif LABEL == 'DISTANCE': #  Total distance travelled (high precision)\n",
    "            PID_TAG = 'spn_917_avg' # 245\n",
    "        elif LABEL == 'SOOTLOAD_3719':\n",
    "            PID_TAG = 'spn_3719_avg' # 245 #3719 generic check  \n",
    "        elif LABEL == 'SOOTLOAD_5466':\n",
    "            PID_TAG = 'spn_5466_avg' # 245 #3719 generic chec         \n",
    "        elif LABEL == 'ACTIVEREGEN':\n",
    "            PID_TAG = 'spn_3700_avg' # 245\n",
    "        elif LABEL == 'PEDAL':\n",
    "            PID_TAG = 'spn_91_avg' # 245  \n",
    "        elif LABEL == 'LOAD':\n",
    "            PID_TAG = 'spn_92_avg' # 245      \n",
    "\n",
    "    elif(PROTOCOL == 'ISO'):\n",
    "\n",
    "        if LABEL == 'IMAP':\n",
    "            PID_TAG = '87BC'#MODIFY the \"if PID_TAG in State1:\" loop (append for loop on top)  \n",
    "        elif LABEL == 'ENGINE LOAD':\n",
    "            PID_TAG = '04'\n",
    "        elif LABEL == 'ENGINE RPM':\n",
    "            PID_TAG = '0C'\n",
    "        elif LABEL == 'FUEL RATE':\n",
    "            PID_TAG = '5E'\n",
    "        elif LABEL == 'MAF':\n",
    "            PID_TAG = '10'\n",
    "        elif LABEL == 'BOOST':\n",
    "            PID_TAG = '102'\n",
    "        elif LABEL == 'BAROMETER':\n",
    "            PID_TAG = '33'\n",
    "        elif LABEL == 'THROTTLE':\n",
    "            PID_TAG = '49'#MODIFY the \"if PID_TAG in State1:\" loop (append for loop on top)\n",
    "        elif LABEL == 'DPFDP': # DPF Diffrential Pressure (across DPF)\n",
    "            PID_TAG = '7A'\n",
    "        elif LABEL == 'DPFDP': # DPF Diffrential Pressure (across DPF)\n",
    "            PID_TAG = '7A'    \n",
    "\n",
    "    #print(LABEL)\n",
    "    print(\"PID TAG is-->\" + LABEL + \" ,\" +PROTOCOL,\"Mapping is --->\", PID_TAG)\n",
    "\n",
    "   \n",
    "\n",
    "    Time_vec = []\n",
    "    Val_vec = []\n",
    "    #print(len(data[0]))\n",
    "    #print(len(data))\n",
    "\n",
    "    for data_cnt in range(0,len(data)):\n",
    "        if \"pids\" in data[data_cnt]:\n",
    "            if len(data[data_cnt]['pids'])>0:\n",
    "                for sub_pid_cnt in range(0,len(data[data_cnt]['pids'])):  #this loop\n",
    "                    State = data[data_cnt]['pids'][sub_pid_cnt]\n",
    "                    #print(State)\n",
    "                    #print(data_cnt)\n",
    "                    #for state_cnt in range(0,len(State)):\n",
    "                    if PID_TAG in State:\n",
    "                        #print(\"--------------------------------------------IN----------------------------------\")\n",
    "                        Time_vec.append(np.array(State[PID_TAG]['timestamp'], dtype=np.int64))\n",
    "                        Val_vec.append(np.array(State[PID_TAG]['value'], dtype=float))\n",
    "\n",
    "    print(\"Number of time stamp available are--->\",len(Val_vec))\n",
    "\n",
    "    \n",
    "    return Time_vec,Val_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Start_TS =  1716834600000\n",
    "End_TS = 1717266540000\n",
    "vehicle = '286461304969625600'\n",
    "\n",
    "# OBD_data_path = \"C:/Users/Harleen.Kaur/Documents/EBT_VEHICLES_FOR_TESTING/1286430381523861504_1716316200000_1717525740000\"\n",
    "\n",
    "\n",
    "# with open(OBD_data_path, 'r') as file:\n",
    "#         OBD_data = json.load(file)\n",
    "OBD_data_path = 'https://old-data-downloader.intangles-aws-us-east-1.intangles.us/download/' + str(vehicle) +  \"/\" + str(Start_TS) + \"/\" + str(End_TS)\n",
    "r = requests.get(OBD_data_path, stream=True)\n",
    "OBD_data = r.json()\n",
    "\n",
    "#C:\\Users\\Harleen.Kaur\\Downloads\\Get_Thresholds.py\n",
    "\n",
    "# OBD_data_path = 'https://old-data-downloader.intangles-aws-us-east-1.intangles.us/download/' + str(vehicle) +  \"/\" + str(Start_TS) + \"/\" + str(End_TS)\n",
    "# r = requests.get(OBD_data_path, stream=True)\n",
    "# OBD_data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as subplots\n",
    "\n",
    "# Create the figure\n",
    "fig = subplots.make_subplots(rows=7, cols=1, shared_xaxes=True)\n",
    "\n",
    "\n",
    "X_Time, X_Value = extract_PID_data(OBD_data,'SAE','DPFDP')\n",
    "DP_val = []\n",
    "TS = []\n",
    "for cnt in range(0,len(X_Time)):\n",
    "    TEMP = datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc)\n",
    "    TS.append(TEMP)\n",
    "    DP_val.append(X_Value[cnt][0])\n",
    "\n",
    "# Add the first trace\n",
    "fig.add_trace(go.Scatter(x=TS, y=DP_val, name='DPFDP', mode='markers' ), row=1, col=1 )\n",
    "\n",
    "fig.add_trace(go.Scatter(x=TS, y=[7]*len(TS), name='Horizontal Line', mode='lines', line=dict(color='red', dash='dash')), row=1, col=1 )\n",
    "\n",
    "\n",
    "X_Time, X_Value = extract_PID_data(OBD_data,'SAE','DPFINT')\n",
    "Temp_val = []\n",
    "TS = []\n",
    "for cnt in range(0,len(X_Time)):\n",
    "    TEMP = datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc)\n",
    "    TS.append(TEMP)\n",
    "    Temp_val.append(X_Value[cnt][0])\n",
    "\n",
    "\n",
    "# Add the second trace\n",
    "fig.add_trace(go.Scatter(x=TS, y=Temp_val, name='DPFINT'), row=2, col=1)   \n",
    "\n",
    "fig.add_trace(go.Scatter(x=TS, y=[500]*len(TS), name='Horizontal Line', mode='lines', line=dict(color='red', dash='dash')), row=2, col=1 )\n",
    "\n",
    "\n",
    "\n",
    "X_Time, X_Value = extract_PID_data(OBD_data,'SAE','ENGINE RPM')\n",
    "Speed_val = []\n",
    "TS = []\n",
    "for cnt in range(0,len(X_Time)):\n",
    "    TEMP = datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc)\n",
    "    TS.append(TEMP)\n",
    "    Speed_val.append(X_Value[cnt][0])\n",
    "\n",
    "# Add the second trace\n",
    "fig.add_trace(go.Scatter(x=TS, y=Speed_val, name='ENGINE RPM'), row=3, col=1)\n",
    "\n",
    "\n",
    "X_Time, X_Value = extract_PID_data(OBD_data,'SAE','SPEED')\n",
    "Speed_val = []\n",
    "TS = []\n",
    "for cnt in range(0,len(X_Time)):\n",
    "    TEMP = datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc)\n",
    "    TS.append(TEMP)\n",
    "    Speed_val.append(X_Value[cnt][0])\n",
    "\n",
    "# Add the second trace\n",
    "fig.add_trace(go.Scatter(x=TS, y=Speed_val, name='SPEED'), row=4, col=1)\n",
    "\n",
    "\n",
    "\n",
    "X_Time, X_Value = extract_PID_data(OBD_data,'SAE','SOOTLOAD_5466')\n",
    "AR_val = []\n",
    "TS = []\n",
    "for cnt in range(0,len(X_Time)):\n",
    "    TEMP = datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc)\n",
    "    TS.append(TEMP)\n",
    "    AR_val.append(X_Value[cnt][0])\n",
    "\n",
    "# Add the second trace\n",
    "fig.add_trace(go.Scatter(x=TS, y=AR_val, name='SOOTLOAD_5466'), row=5, col=1)  \n",
    "\n",
    "\n",
    "X_Time, X_Value = extract_PID_data(OBD_data,'SAE','SOOTLOAD_3719')\n",
    "AR_val = []\n",
    "TS = []\n",
    "for cnt in range(0,len(X_Time)):\n",
    "    TEMP = datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc)\n",
    "    TS.append(TEMP)\n",
    "    AR_val.append(X_Value[cnt][0])\n",
    "\n",
    "# Add the second trace\n",
    "fig.add_trace(go.Scatter(x=TS, y=AR_val, name='SOOTLOAD_3719'), row=6, col=1)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_Time, X_Value = extract_PID_data(OBD_data,'SAE','ACTIVEREGEN')\n",
    "AR_val = []\n",
    "TS = []\n",
    "for cnt in range(0,len(X_Time)):\n",
    "    TEMP = datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc)\n",
    "    TS.append(TEMP)\n",
    "    AR_val.append(X_Value[cnt][0])\n",
    "\n",
    "# Add the second trace\n",
    "fig.add_trace(go.Scatter(x=TS, y=AR_val, name='ACTIVEREGEN', mode='markers'), row=7, col=1)    \n",
    "\n",
    "\n",
    "# Set the y-axis titles\n",
    "fig.update_layout(yaxis1_title='DPFDP', yaxis2_title='DPFINT', yaxis3_title='ENGINE RPM', yaxis4_title='SPEED', yaxis5_title='SOOTLOAD_5466',\n",
    "                  yaxis6_title='SOOTLOAD_3719',\n",
    "                  yaxis7_title='ACTIVEREGEN')    \n",
    "\n",
    "\n",
    "# X_Time, X_Value = extract_PID_data(OBD_data,'SAE','SPEED')\n",
    "# Speed_val = []\n",
    "# TS = []\n",
    "# for cnt in range(0,len(X_Time)):\n",
    "#     TEMP = datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0)\n",
    "#     TS.append(TEMP)\n",
    "#     Speed_val.append(X_Value[cnt][0])\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "#fig.write_html(\"C:/Users/Harleen.Kaur/Documents/EBT_VEHICLES_FOR_TESTING/RWTL/\" + \"1286430381523861504_1716316200000_1717525740000.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Time, X_Value = extract_PID_data(OBD_data,'SAE','SOOTLOAD_5466')\n",
    "SL_val = []\n",
    "TS = []\n",
    "for cnt in range(0,len(X_Time)):\n",
    "    TEMP = datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc)\n",
    "    TS.append(TEMP)\n",
    "    SL_val.append(X_Value[cnt][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_idx = (np.abs(np.asarray(X_Time) - (1716575400000))).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = []\n",
    "for i in range(relevant_idx + 1, len(SL_val)):\n",
    "    difference.append(SL_val[i]-SL_val[i-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = []\n",
    "for i in range(1, len(SL_val)-1):\n",
    "    if SL_val[i] > SL_val[i-1] and SL_val[i-1]!=0:\n",
    "        difference.append((SL_val[i]-SL_val[i-1])/SL_val[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(difference).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temporary Portion above will be deleted Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/Harleen.Kaur/Downloads/Spec Object\", \"r\") as file:\n",
    "    json_data = file.read()\n",
    "data = json.loads(json_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"additional_info\"]['dpf_soot_loading_pid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_ID = 1281385415655292928\n",
    "Start_TS = str(int(1714454580000))\n",
    "End_TS   = str(int(1716661740000))\n",
    "\n",
    "\n",
    "local_filename = 'D:/products/EBT_VEHICLE_DATA_FOR_TESTING/'  + str(vehicle_ID) + \"_\" + str(Start_TS) + \"_\" + str(End_TS)\n",
    "\n",
    "# for Indian vehicles use the API 'http://data-download.intangles.com:1883/download/'\n",
    "# for US vehicles use the API http://algo-internal-apis.intangles-aws-us-east-1.intangles.us:1883/download/\n",
    "URL = 'https://old-data-downloader.intangles-aws-us-east-1.intangles.us/download/' + str(vehicle_ID) +  \"/\" + str(Start_TS) + \"/\" + str(End_TS)\n",
    "\n",
    "\n",
    "\n",
    "print(URL)\n",
    "\n",
    "r = requests.get(URL,stream=True)\n",
    "\n",
    "print(\"this is the response: \", r)\n",
    "\n",
    "with open(local_filename, 'wb') as f:\n",
    "    for chunk in r.iter_content(chunk_size=1024):\n",
    "        if chunk:\n",
    "            print(\"WRITING...........\")\n",
    "            f.write(chunk)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "# C:\\Users\\Harleen.Kaur\\Downloads\\Get_Thresholds.py\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx],idx\n",
    "\n",
    "def extract_PID_data(data, PROTOCOL,LABEL):\n",
    "    \n",
    "    if (PROTOCOL == 'SAE'):\n",
    "\n",
    "        if LABEL == 'IMAP':\n",
    "            PID_TAG = 'spn_106_avg'\n",
    "        elif LABEL == 'ENGINE LOAD':\n",
    "            PID_TAG = 'spn_92_avg'\n",
    "        elif LABEL == 'ENGINE RPM':\n",
    "            PID_TAG = 'spn_190_avg'\n",
    "        elif LABEL == 'FUEL RATE':\n",
    "            PID_TAG = 'spn_183_avg'\n",
    "        elif LABEL == 'MAF':\n",
    "            PID_TAG = 'spn_132_avg'\n",
    "        elif LABEL == 'BOOST':\n",
    "            PID_TAG = 'spn_102_avg'\n",
    "        elif LABEL == 'BAROMETER':\n",
    "            PID_TAG = 'spn_108_avg'\n",
    "        elif LABEL == 'THROTTLE':\n",
    "            PID_TAG = 'spn_91_avg'\n",
    "        elif LABEL == 'ATGMF': # Eaxuast Gas Flow Rate\n",
    "            PID_TAG = 'spn_3236_avg'\n",
    "        elif LABEL == 'DPFDP': # DPF Diffrential Pressure (across DPF)\n",
    "            PID_TAG = 'spn_3251_avg'\n",
    "        elif LABEL == 'SCRT':   # SCR Catalyst Temperature Before Catalyst (DPF out)\n",
    "            PID_TAG = 'spn_4360_avg'\n",
    "        elif LABEL == 'SPEED': # Wheep based Vehicle Speed\n",
    "            PID_TAG = 'spn_84_avg'\n",
    "        elif LABEL == 'DPFINT':# DPF in Temperature Before DPF (DOC out)\n",
    "            PID_TAG = 'spn_3250_avg' #4766\n",
    "        elif LABEL == 'IS': #  regen inhibited\n",
    "            PID_TAG = 'spn_3703_avg'        \n",
    "        elif LABEL == 'FUEL USE': #  Total fuel used (high precision)\n",
    "            PID_TAG = 'spn_5054_avg'        \n",
    "        elif LABEL == 'DISTANCE': #  Total distance travelled (high precision)\n",
    "            PID_TAG = 'spn_917_avg' # 245\n",
    "        elif LABEL == 'SOOTLOAD':\n",
    "            PID_TAG = 'spn_5466_avg' # 245 #3719 generic check       \n",
    "        elif LABEL == 'ACTIVEREGEN':\n",
    "            PID_TAG = 'spn_3700_avg' # 245\n",
    "        elif LABEL == 'PEDAL':\n",
    "            PID_TAG = 'spn_91_avg' # 245  \n",
    "        elif LABEL == 'LOAD':\n",
    "            PID_TAG = 'spn_92_avg' # 245      \n",
    "\n",
    "    elif(PROTOCOL == 'ISO'):\n",
    "\n",
    "        if LABEL == 'IMAP':\n",
    "            PID_TAG = '87BC'#MODIFY the \"if PID_TAG in State1:\" loop (append for loop on top)  \n",
    "        elif LABEL == 'ENGINE LOAD':\n",
    "            PID_TAG = '04'\n",
    "        elif LABEL == 'ENGINE RPM':\n",
    "            PID_TAG = '0C'\n",
    "        elif LABEL == 'FUEL RATE':\n",
    "            PID_TAG = '5E'\n",
    "        elif LABEL == 'MAF':\n",
    "            PID_TAG = '10'\n",
    "        elif LABEL == 'BOOST':\n",
    "            PID_TAG = '102'\n",
    "        elif LABEL == 'BAROMETER':\n",
    "            PID_TAG = '33'\n",
    "        elif LABEL == 'THROTTLE':\n",
    "            PID_TAG = '49'#MODIFY the \"if PID_TAG in State1:\" loop (append for loop on top)\n",
    "        elif LABEL == 'DPFDP': # DPF Diffrential Pressure (across DPF)\n",
    "            PID_TAG = '7A'\n",
    "        elif LABEL == 'DPFDP': # DPF Diffrential Pressure (across DPF)\n",
    "            PID_TAG = '7A'    \n",
    "\n",
    "    #print(LABEL)\n",
    "    print(\"PID TAG is-->\" + LABEL + \" ,\" +PROTOCOL,\"Mapping is --->\", PID_TAG)\n",
    "\n",
    "   \n",
    "\n",
    "    Time_vec = []\n",
    "    Val_vec = []\n",
    "    #print(len(data[0]))\n",
    "    #print(len(data))\n",
    "\n",
    "    for data_cnt in range(0,len(data)):\n",
    "        if \"pids\" in data[data_cnt]:\n",
    "            if len(data[data_cnt]['pids'])>0:\n",
    "                for sub_pid_cnt in range(0,len(data[data_cnt]['pids'])):  #this loop\n",
    "                    State = data[data_cnt]['pids'][sub_pid_cnt]\n",
    "                    #print(State)\n",
    "                    #print(data_cnt)\n",
    "                    #for state_cnt in range(0,len(State)):\n",
    "                    if PID_TAG in State:\n",
    "                        #print(\"--------------------------------------------IN----------------------------------\")\n",
    "                        Time_vec.append(np.array(State[PID_TAG]['timestamp'], dtype=np.int64))\n",
    "                        Val_vec.append(np.array(State[PID_TAG]['value'], dtype=float))\n",
    "\n",
    "    print(\"Number of time stamp avilables are--->\",len(Val_vec))\n",
    "\n",
    "    \n",
    "    return Time_vec,Val_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # ... (rest of the code remains the same)\n",
    "    vehicle =  1281385415655292928\n",
    "    #imei = 866834049482107 \n",
    "    # reading the OBD-Data one hour prior and one-hour after the regeneration time\n",
    "    Start_TS =  1714501800000  - 1*60*60*1000\n",
    "    End_TS = 1716661740000 + 1*60*60*1000\n",
    "\n",
    "    OBD_data_path = 'https://old-data-downloader.intangles-aws-us-east-1.intangles.us/download/' + str(vehicle) +  \"/\" + str(Start_TS) + \"/\" + str(End_TS)\n",
    "    r = requests.get(OBD_data_path, stream=True)\n",
    "    OBD_data = r.json()\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    LABEL = 'DPFDP'\n",
    "    X_Time, X_Value = extract_PID_data(OBD_data, 'SAE', LABEL)\n",
    "    TS = [datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc) for cnt in range(0, len(X_Time))]\n",
    "    fig.add_trace(go.Scatter(x=TS, y=X_Value, mode='markers', name=LABEL))\n",
    "    fig.add_hline(y=7, line_color='red', line_dash='dash')\n",
    "\n",
    "    LABEL = 'DPFINT'\n",
    "    X_Time, X_Value = extract_PID_data(OBD_data, 'SAE', LABEL)\n",
    "    TS = [datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc) for cnt in range(0, len(X_Time))]\n",
    "    fig.add_trace(go.Scatter(x=TS, y=X_Value, mode='lines', name=LABEL))\n",
    "    fig.add_hline(y=500, line_color='red', line_dash='dash')\n",
    "\n",
    "    LABEL = 'ATGMF'\n",
    "    X_Time, X_Value = extract_PID_data(OBD_data, 'SAE', LABEL)\n",
    "    TS = [datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc) for cnt in range(0, len(X_Time))]\n",
    "    fig.add_trace(go.Scatter(x=TS, y=X_Value, mode='lines', name=LABEL))\n",
    "\n",
    "    LABEL = 'ENGINE RPM'\n",
    "    X_Time, X_Value = extract_PID_data(OBD_data, 'SAE', LABEL)\n",
    "    TS = [datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc) for cnt in range(0, len(X_Time))]\n",
    "    fig.add_trace(go.Scatter(x=TS, y=X_Value, mode='lines', name=LABEL))\n",
    "\n",
    "    LABEL = 'THROTTLE'\n",
    "    X_Time, X_Value = extract_PID_data(OBD_data, 'SAE', LABEL)\n",
    "    TS = [datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc) for cnt in range(0, len(X_Time))]\n",
    "    fig.add_trace(go.Scatter(x=TS, y=X_Value, mode='lines', name=LABEL))\n",
    "\n",
    "    LABEL = 'ENGINE LOAD'\n",
    "    X_Time, X_Value = extract_PID_data(OBD_data, 'SAE', LABEL)\n",
    "    TS = [datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc) for cnt in range(0, len(X_Time))]\n",
    "    fig.add_trace(go.Scatter(x=TS, y=X_Value, mode='lines', name=LABEL))\n",
    "\n",
    "    LABEL = 'SPEED'\n",
    "    X_Time, X_Value = extract_PID_data(OBD_data, 'SAE', LABEL)\n",
    "    TS = [datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc) for cnt in range(0, len(X_Time))]\n",
    "    fig.add_trace(go.Scatter(x=TS, y=X_Value, mode='lines', name=LABEL))\n",
    "\n",
    "    LABEL = 'IS'\n",
    "    X_Time, X_Value = extract_PID_data(OBD_data, 'SAE', LABEL)\n",
    "    TS = [datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc) for cnt in range(0, len(X_Time))]\n",
    "    fig.add_trace(go.Scatter(x=TS, y=X_Value, mode='lines', name=LABEL))\n",
    "\n",
    "    LABEL = 'SOOTLOAD'\n",
    "    X_Time, X_Value = extract_PID_data(OBD_data, 'SAE', LABEL)\n",
    "    TS = [datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc) for cnt in range(0, len(X_Time))]\n",
    "    fig.add_trace(go.Scatter(x=TS, y=X_Value, mode='lines', name=LABEL))\n",
    "\n",
    "    LABEL = 'PEDAL'\n",
    "    X_Time, X_Value = extract_PID_data(OBD_data, 'SAE', LABEL)\n",
    "    TS = [datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc) for cnt in range(0, len(X_Time))]\n",
    "    fig.add_trace(go.Scatter(x=TS, y=X_Value, mode='lines', name=LABEL))\n",
    "\n",
    "    LABEL = 'ACTIVEREGEN'\n",
    "    X_Time, X_Value = extract_PID_data(OBD_data, 'SAE', LABEL)\n",
    "    TS = [datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc) for cnt in range(0, len(X_Time))]\n",
    "    fig.add_trace(go.Scatter(x=TS, y=X_Value, mode='lines', name=LABEL))\n",
    "\n",
    "    fig.update_layout(title_text=\"Vehicle Data\", xaxis_title=\"Time\", yaxis_title=\"Value\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_pid = 'spn_3251_avg'\n",
    "rpm_pid = 'spn_190_avg'\n",
    "speed_pid = 'spn_84_avg'\n",
    "soot_load_pid = 'spn_5466_avg'\n",
    "Time = []\n",
    "dp_inst_Value = []\n",
    "rpm_inst_Value = []\n",
    "speed_inst_Value =[]\n",
    "for pac_idx in range(len(OBD_data)):\n",
    "        if \"pids\" in OBD_data[pac_idx]:\n",
    "            if len(OBD_data[pac_idx]['pids'])>0:\n",
    "                for sub_pid_cnt in range(0,len(OBD_data[pac_idx]['pids'])):\n",
    "                        State = OBD_data[pac_idx]['pids'][sub_pid_cnt]\n",
    "                        # extracting DPFDP\n",
    "                        if dp_pid in State:\n",
    "                                Time.append(State[dp_pid]['timestamp'])\n",
    "                                dp_inst_Value.append(State[dp_pid]['value'][0])\n",
    "                        # extracting RPM        \n",
    "                        if rpm_pid in State:\n",
    "                                rpm_inst_Value.append(State[rpm_pid]['value'][0])\n",
    "                        # extracting SPEED       \n",
    "                        if speed_pid in State:\n",
    "                                speed_inst_Value.append(State[speed_pid]['value'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "#from app.dataIO import get_obd_data \n",
    "\n",
    "\n",
    "\n",
    "# function to be called for making the active-regeneration point shift\n",
    "def active_regeneration_shift(OBD_data, active_regeneration_start_time, spec_obj):\n",
    "        \n",
    "        # extracting the relevant soot-load parameter-ID\n",
    "        soot_load_pid = '5466'\n",
    "        if 'dpf_soot_loading_pid' in spec_obj[\"additional_info\"]:\n",
    "               soot_load_pid = spec_obj[\"additional_info\"]['dpf_soot_loading_pid']\n",
    "        \n",
    "        Time = []\n",
    "        soot_load_Value = []\n",
    "        for pac_idx in range(len(OBD_data)):\n",
    "                if \"pids\" in OBD_data[pac_idx]:\n",
    "                    if len(OBD_data[pac_idx]['pids'])>0:\n",
    "                        for sub_pid_cnt in range(0,len(OBD_data[pac_idx]['pids'])):\n",
    "                                State = OBD_data[pac_idx]['pids'][sub_pid_cnt]\n",
    "                                # extracting Soot-Load\n",
    "                                if soot_load_pid in State:\n",
    "                                        Time.append(State[soot_load_pid]['timestamp'])\n",
    "                                        soot_load_Value.append(State[soot_load_pid]['value'][0])\n",
    "        \n",
    "        # if soot_load values not available\n",
    "        if len(soot_load_Value)==0:\n",
    "               return active_regeneration_start_time\n",
    "        \n",
    "        # if soot load values are available --> find the point where maximum negative slope present\n",
    "        slope = np.array(soot_load_Value[1:-1]) - np.array(soot_load_Value[0:-2])\n",
    "        adjusted_index = np.argmin(slope)\n",
    "\n",
    "        # if the point of maximum drop is greater than 10 minutes\n",
    "        # search for the maximum drop wthin 10 minutes prior to active-regeneration time\n",
    "        if (active_regeneration_start_time - Time[adjusted_index-1])>(10*60*1000):\n",
    "                idx_10_mins_before = (np.abs(np.asarray(Time) - (active_regeneration_start_time - 10*60*1000))).argmin()\n",
    "                adjusted_index = idx_10_mins_before\n",
    "        if (Time[adjusted_index-1]-active_regeneration_start_time)>(10*60*1000):\n",
    "                idx_10_mins_after = (np.abs(np.asarray(Time) - (active_regeneration_start_time + 10*60*1000))).argmin()\n",
    "                adjusted_index = idx_10_mins_after       \n",
    "                        \n",
    "\n",
    "        return Time[adjusted_index-1]\n",
    "                                      \n",
    "\n",
    "\n",
    "# function to be called for generation regeneration evidence\n",
    "def regeneration_evidence(COUNTRY_FLAG, OBD_data,\n",
    "                            active_regeneration_start_time, active_regeneration_end_time, \n",
    "                            burn_quality_percentage):\n",
    "    \n",
    "    \n",
    "                \n",
    "        # getting the active-regeneration duration in minutes\n",
    "        active_regeneration_duration = (active_regeneration_end_time - active_regeneration_start_time)//(60*1000)\n",
    "        \n",
    "        # corner case\n",
    "        # if active_regeneration_start_time >= active_regeneration_end_time \n",
    "        # active_regeneration_duration happens to be less that 10 minutes\n",
    "        if (active_regeneration_start_time >= active_regeneration_end_time) or (active_regeneration_duration <= 10):\n",
    "                # check the status of burn_quality\n",
    "                # if burn_quality == high  --> Set the speed status sufficient (1)\n",
    "                # else --> Set the speed status insufficient (0)\n",
    "                if burn_quality_percentage>=0.6 and burn_quality_percentage!=2:\n",
    "                        speed_status = 1\n",
    "                else:\n",
    "                        speed_status = 0        \n",
    "                return speed_status, burn_quality_percentage\n",
    "\n",
    "        \n",
    "        \n",
    "        # if FLAG is set to \"US\" use the following RPM and Speed thresholds\n",
    "        if COUNTRY_FLAG == 'US':\n",
    "                RPM_RANGE = [800, 2000]\n",
    "                SPEED_THRESHOLD = 80\n",
    "\n",
    "        # if FLAG is set to \"IN\" use the following RPM and Speed thresholds\n",
    "        elif COUNTRY_FLAG == 'IN':\n",
    "                RPM_RANGE = [1000, 2000]\n",
    "                SPEED_THRESHOLD = 40\n",
    " \n",
    "\n",
    "        # extracting the relevant parameter-ID\n",
    "        dp_pid = 'spn_3251_avg'\n",
    "        rpm_pid = 'spn_190_avg'\n",
    "        speed_pid = 'spn_84_avg'\n",
    "        Time = []\n",
    "        dp_inst_Value = []\n",
    "        rpm_inst_Value = []\n",
    "        speed_inst_Value =[]\n",
    "        for pac_idx in range(len(OBD_data)):\n",
    "                if \"pids\" in OBD_data[pac_idx]:\n",
    "                    if len(OBD_data[pac_idx]['pids'])>0:\n",
    "                        for sub_pid_cnt in range(0,len(OBD_data[pac_idx]['pids'])):\n",
    "                                State = OBD_data[pac_idx]['pids'][sub_pid_cnt]\n",
    "                                # extracting DPFDP\n",
    "                                if dp_pid in State:\n",
    "                                        Time.append(State[dp_pid]['timestamp'])\n",
    "                                        dp_inst_Value.append(State[dp_pid]['value'][0])\n",
    "                                # extracting RPM        \n",
    "                                if rpm_pid in State:\n",
    "                                        rpm_inst_Value.append(State[rpm_pid]['value'][0])\n",
    "                                # extracting SPEED       \n",
    "                                if speed_pid in State:\n",
    "                                        speed_inst_Value.append(State[speed_pid]['value'][0])    \n",
    "\n",
    "                                             \n",
    "                                \n",
    "        # applying the RPM constraint\n",
    "        # getting the correspnding values of different varaibles after applying constraints\n",
    "        # Time1 constitutes of timestamps where the RPM conditions are met\n",
    "        dp_rpm_constrained = []\n",
    "        speed_rpm_constrained = []\n",
    "        Time1 = []\n",
    "        rpm_constrained = []\n",
    "\n",
    "        # iterating through each timestamp to make the RPM constraint check\n",
    "        for i in range(len(Time)):\n",
    "            if rpm_inst_Value[i]>=RPM_RANGE[0] and rpm_inst_Value[i]<=RPM_RANGE[-1]:\n",
    "                    dp_rpm_constrained.append(dp_inst_Value[i])\n",
    "                    Time1.append(Time[i])\n",
    "                    rpm_constrained.append(rpm_inst_Value[i])\n",
    "                    speed_rpm_constrained.append(speed_inst_Value[i])\n",
    "        \n",
    "        # after applying the rpm-constraint check which are the nearest active regeneration start and end indices\n",
    "        nearest_ar_start_idx = (np.abs(np.array(Time1) -  active_regeneration_start_time)).argmin()\n",
    "        nearest_ar_end_idx = (np.abs(np.array(Time1) -  active_regeneration_end_time)).argmin()\n",
    "        \n",
    "        # if the nearest start and end indices comes out to be same (which implies after applying the rpm-constraint we are \n",
    "        # not left with any valid point)\n",
    "        if (nearest_ar_start_idx == nearest_ar_end_idx):\n",
    "                if burn_quality_percentage>=0.6 and burn_quality_percentage!=2:\n",
    "                        speed_status = 1\n",
    "                else:\n",
    "                        speed_status = 0\n",
    "                return speed_status, burn_quality_percentage\n",
    "                \n",
    "\n",
    "\n",
    "        # calculating the mid-region of the active regeneration zone\n",
    "        mid_idx = (nearest_ar_start_idx + nearest_ar_end_idx)//2\n",
    "\n",
    "        # bringing both the pre and post window to same sizes\n",
    "        pre_start_idx = 0\n",
    "        post_end_idx = len(Time1)\n",
    "        # if length of the pre-regeneration window > length of the post-regeneration window\n",
    "        # bring the pre-window to same size as the post window\n",
    "        if (mid_idx) > (len(Time1)- nearest_ar_end_idx):\n",
    "                pre_start_idx = mid_idx - (len(Time1)- nearest_ar_end_idx)\n",
    "        # if length of the pre-regeneration window < length of the post-regeneration window  \n",
    "        # bring the post-window to same size as the pre window\n",
    "        elif (mid_idx) < (len(Time1)- nearest_ar_end_idx):\n",
    "                post_end_idx = nearest_ar_end_idx + mid_idx \n",
    "        \n",
    "        # fixing the pre_dp, pre_rpm and the pre_speed window\n",
    "        pre_dp_window = dp_rpm_constrained[pre_start_idx:mid_idx]\n",
    "        pre_rpm_window = rpm_constrained[pre_start_idx:mid_idx]\n",
    "        pre_speed_window = speed_rpm_constrained[pre_start_idx:mid_idx]\n",
    "\n",
    "        # fixing the post_dp, post_rpm and the post_speed window\n",
    "        post_dp_window = dp_rpm_constrained[nearest_ar_end_idx:post_end_idx]\n",
    "        post_rpm_window = rpm_constrained[nearest_ar_end_idx:post_end_idx]\n",
    "        post_speed_window = speed_rpm_constrained[nearest_ar_end_idx:post_end_idx]\n",
    "        \n",
    "        # quantifying the burn_quality basis the burn_quality_percentage\n",
    "        #   0 <= burn_quality_percentage < 0.33 --> low burn_quality\n",
    "        if (burn_quality_percentage>=0 and burn_quality_percentage<0.33):\n",
    "                burn_quality = 'low'\n",
    "        #   0.33 <= burn_quality_percentage < 0.66 --> medium burn_quality        \n",
    "        elif (burn_quality_percentage>=0.33 and burn_quality_percentage<0.66):\n",
    "                burn_quality = 'medium' \n",
    "        #   0.66 <= burn_quality_percentage < 1 --> high burn_quality        \n",
    "        elif (burn_quality_percentage>=0.66 and burn_quality_percentage<1):\n",
    "                burn_quality = 'high' \n",
    "        #  burn_quality_percentage == 2 --> failed burn            \n",
    "        elif burn_quality_percentage == 2:\n",
    "                burn_quality = 'failed'\n",
    "\n",
    "        # reconcilation logic for low and high burn-quality        \n",
    "        if (burn_quality == 'low') or (burn_quality == 'high'):\n",
    "            \n",
    "            # getting the partition for breaking the rpm-bins into two equal bins \n",
    "            bin_size = (RPM_RANGE[-1]-RPM_RANGE[0])//2       \n",
    "            # getting the columns (we are capturing the count and mean of the dp values in each of the rpm-bins)\n",
    "            columns = [\n",
    "                    'RPM Bin', 'Speed Bin', 'Count', \n",
    "                    'Mean'\n",
    "                    ]\n",
    "\n",
    "            # capturing the decriptive statistics, and their corresponding rpm and speed bin\n",
    "            df_pre_statistics_all_vehicles = pd.DataFrame(columns = columns)\n",
    "            df_post_statistics_all_vehicles = pd.DataFrame(columns = columns)\n",
    "\n",
    "            pre_descriptive_statistics_all_bins = []\n",
    "            post_descriptive_statistics_all_bins = []\n",
    "            pre_rpm_bin_considered = []\n",
    "            post_rpm_bin_considered = []\n",
    "            pre_speed_bin_considered = []\n",
    "            post_speed_bin_considered = []\n",
    "\n",
    "            # getting the RPM_RANGE and creating bin on those\n",
    "            for bin in range(RPM_RANGE[0],  RPM_RANGE[-1], bin_size):\n",
    "                    # creating the low and high speed bins for each of the rpm-bins\n",
    "                    # getting the pre-bins\n",
    "                    pre_dp_in_rpm_low_speed_bin = []\n",
    "                    pre_dp_in_rpm_high_speed_bin = []\n",
    "                    # getting the post-bins\n",
    "                    post_dp_in_rpm_low_speed_bin = []\n",
    "                    post_dp_in_rpm_high_speed_bin = []\n",
    "\n",
    "\n",
    "                    # parsing through all the enteries of the dp-window\n",
    "                    for j in range(len(pre_dp_window)):  \n",
    "                            \n",
    "                            # if the rpm values are between the bin & (bin+bin_size)\n",
    "\n",
    "                            # checking the above condition for pre-rpm window\n",
    "                            if pre_rpm_window[j]>= bin and pre_rpm_window[j] < (bin+bin_size):\n",
    "                                    # getting the dp in the low-speed zone of specific rpm-zone\n",
    "                                    if int(pre_speed_window[j]) <= SPEED_THRESHOLD:\n",
    "                                            pre_dp_in_rpm_low_speed_bin.append(pre_dp_window[j])\n",
    "                                    # getting the dp in the high-speed zone of specific rpm-zone    \n",
    "                                    else:\n",
    "                                            pre_dp_in_rpm_high_speed_bin.append(pre_dp_window[j])   \n",
    "                            \n",
    "                            # checking the above condition for the post-window\n",
    "                            if post_rpm_window[j]>= bin and post_rpm_window[j] < (bin + bin_size):  \n",
    "                                    # getting the dp in the low-speed zone of specific rpm-zone\n",
    "                                    if int(post_speed_window[j]) <= SPEED_THRESHOLD:\n",
    "                                            post_dp_in_rpm_low_speed_bin.append(post_dp_window[j])\n",
    "                                    # getting the dp in the high-speed zone of specific rpm-zone    \n",
    "                                    else:\n",
    "                                            post_dp_in_rpm_high_speed_bin.append(post_dp_window[j])             \n",
    "\n",
    "                    # if rpm with lower-speed bin\n",
    "                    if len(pre_dp_in_rpm_low_speed_bin) > 0:\n",
    "                            summary_statistics =  pd.DataFrame(pre_dp_in_rpm_low_speed_bin).describe()  \n",
    "                            pre_descriptive_statistics_all_bins.append([\n",
    "                                                            summary_statistics.loc['count'][0],\n",
    "                                                            summary_statistics.loc['mean'][0], \n",
    "                                                            ]) \n",
    "                            pre_rpm_bin_considered.append((bin, (bin+bin_size)))\n",
    "                            pre_speed_bin_considered.append(\"<=\"+str(SPEED_THRESHOLD))\n",
    "                                            \n",
    "                    if len(post_dp_in_rpm_low_speed_bin) > 0:\n",
    "                            summary_statistics =  pd.DataFrame(post_dp_in_rpm_low_speed_bin).describe()  \n",
    "                            post_descriptive_statistics_all_bins.append([\n",
    "                                                            summary_statistics.loc['count'][0],\n",
    "                                                            summary_statistics.loc['mean'][0] \n",
    "                                                    ]) \n",
    "                            post_rpm_bin_considered.append((bin, (bin+bin_size)))\n",
    "                            post_speed_bin_considered.append(\"<=\"+str(SPEED_THRESHOLD))\n",
    "\n",
    "\n",
    "                    # if rpm with higher-speed bin                \n",
    "                    if len(pre_dp_in_rpm_high_speed_bin) > 0:\n",
    "                            summary_statistics =  pd.DataFrame(pre_dp_in_rpm_high_speed_bin).describe()  \n",
    "                            pre_descriptive_statistics_all_bins.append([\n",
    "                                                            summary_statistics.loc['count'][0],\n",
    "                                                            summary_statistics.loc['mean'][0]]) \n",
    "                            pre_rpm_bin_considered.append((bin, (bin+bin_size)))\n",
    "                            pre_speed_bin_considered.append(\">\"+str(SPEED_THRESHOLD))\n",
    "\n",
    "                    if len(post_dp_in_rpm_high_speed_bin) > 0:\n",
    "                            summary_statistics =  pd.DataFrame(post_dp_in_rpm_high_speed_bin).describe()  \n",
    "                            post_descriptive_statistics_all_bins.append([\n",
    "                                                                    summary_statistics.loc['count'][0],\n",
    "                                                                    summary_statistics.loc['mean'][0]]) \n",
    "                            post_rpm_bin_considered.append((bin, (bin+bin_size)))\n",
    "                            post_speed_bin_considered.append(\">\"+str(SPEED_THRESHOLD))   \n",
    "                                                            \n",
    "                                    \n",
    "            if len(pre_descriptive_statistics_all_bins):\n",
    "                for j in range(len(pre_descriptive_statistics_all_bins)):  \n",
    "                        pre_row_data = []\n",
    "                        pre_row_data.append(pre_rpm_bin_considered[j]) #'RPM Bin'\n",
    "                        pre_row_data.append(pre_speed_bin_considered[j]) #'Speed Bin'\n",
    "                        pre_row_data.extend(pre_descriptive_statistics_all_bins[j]) \n",
    "                        df_pre_statistics_all_vehicles.loc[len(df_pre_statistics_all_vehicles)] = pre_row_data\n",
    "        \n",
    "            if len(post_descriptive_statistics_all_bins):\n",
    "                for j in range(len(post_descriptive_statistics_all_bins)):\n",
    "                        post_row_data = []  \n",
    "                        post_row_data.append(post_rpm_bin_considered[j]) #'RPM Bin'\n",
    "                        post_row_data.append(post_speed_bin_considered[j]) #'Speed Bin'\n",
    "                        post_row_data.extend(post_descriptive_statistics_all_bins[j]) \n",
    "                        df_post_statistics_all_vehicles.loc[len(df_post_statistics_all_vehicles)] = post_row_data\n",
    "\n",
    "            # dropping off duplicates from pre and post dataframe\n",
    "            df_pre_statistics_all_vehicles = df_pre_statistics_all_vehicles.drop_duplicates()\n",
    "            df_post_statistics_all_vehicles = df_post_statistics_all_vehicles.drop_duplicates()\n",
    "\n",
    "            print(\"this is the pre-statistics: \")\n",
    "            print(df_pre_statistics_all_vehicles)\n",
    "\n",
    "            print(\"this is the pre-statistics: \")\n",
    "            print(df_post_statistics_all_vehicles)\n",
    "\n",
    "            # renaming the columns for pre and post statistical dataframes\n",
    "            df_pre_statistics_all_vehicles.columns = [\"Pre RPM Bin\", \"Pre Speed Bin\", \n",
    "                                                    \"Pre Count\", \"Pre Mean\"]\n",
    "                    \n",
    "            df_post_statistics_all_vehicles.columns = [\"Post RPM Bin\", \"Post Speed Bin\", \n",
    "                                                    \"Post Count\", \"Post Mean\"]\n",
    "                    \n",
    "            print(\"this is the pre-statistics: \", df_pre_statistics_all_vehicles)\n",
    "\n",
    "            print(\"this is the post-statistics: \", df_post_statistics_all_vehicles)\n",
    "            \n",
    "            \n",
    "            # combining pre and post dataframes basis RPM and SPEED bin values \n",
    "            df_statistics = pd.merge(df_pre_statistics_all_vehicles, df_post_statistics_all_vehicles, how='inner', \n",
    "                                    left_on=[\"Pre RPM Bin\", \"Pre Speed Bin\"],\n",
    "                                    right_on = [\"Post RPM Bin\", \"Post Speed Bin\"])\n",
    "                    \n",
    "            # In case any duplicates generated while combining the two dataframes drop them\n",
    "            if df_statistics.shape[0]>0:\n",
    "\n",
    "                df_statistics = df_statistics.drop_duplicates()\n",
    "\n",
    "                print(\"this is the df_statistics using the version-1: \", df_statistics) \n",
    "\n",
    "                # dropping all those statistical bins wherein the Pre or Post Count of values are less than 5\n",
    "                indices_remove = df_statistics[(df_statistics['Pre Count']<5) | (df_statistics['Post Count']<5)].index\n",
    "                df_statistics.drop(indices_remove, inplace=True)\n",
    "\n",
    "                \n",
    "                \n",
    "                fraction_good_bins = df_statistics[(df_statistics[\"Post Mean\"]<df_statistics[\"Pre Mean\"])].shape[0]/df_statistics.shape[0]\n",
    "\n",
    "\n",
    "                print(\"these are the fraction of good-bins using the version-1: \", fraction_good_bins)\n",
    "                \n",
    "        \n",
    "                # for \"high\" soot burn\n",
    "                # the logic goes something like this\n",
    "                # if 0/4 bins has the post-dp < pre-dp, classify as low\n",
    "                # if 1/4 or 2/4 has the post-dp < pre-dp, classify as medium \n",
    "                if burn_quality == 'high' and fraction_good_bins == 0:\n",
    "                        burn_quality = 'low'\n",
    "                        burn_quality_percentage = burn_quality_percentage/3\n",
    "                elif burn_quality == 'high' and fraction_good_bins <= 0.5 and fraction_good_bins != 0:\n",
    "                        burn_quality = 'medium'\n",
    "                        burn_quality_percentage = burn_quality_percentage/2   \n",
    "\n",
    "                # for \"low\" soot burn\n",
    "                # the logic goes something like this\n",
    "                # if 3/4 or 4/4 has the post-dp < pre-dp, classify as medium \n",
    "                if burn_quality == 'low' and fraction_good_bins > 0.5:\n",
    "                        burn_quality = 'medium'\n",
    "                        burn_quality_percentage = burn_quality_percentage * 2\n",
    "        high_speed_count = 0\n",
    "        # giving the duration and speed status for each of the moderate and low burn_quality\n",
    "        if burn_quality != 'high':     \n",
    "                # if for atleast 50% of the time; the vehicle is running at required speed  \n",
    "                # then set the speed status to sufficient i.e. 1        \n",
    "                for speed in speed_inst_Value:\n",
    "                        if speed >= SPEED_THRESHOLD:\n",
    "                                high_speed_count += 1\n",
    "                # if for atleast 50% of the time speed happens to be high during regeneration                \n",
    "                if high_speed_count/len(speed_inst_Value) > 0.5:    \n",
    "                        speed_status = 1\n",
    "                        \n",
    "                elif  high_speed_count/len(speed_inst_Value) <= 0.5: \n",
    "                        speed_status = 0\n",
    "        # if burn_quality is high ; keep the speed status sufficient               \n",
    "        elif burn_quality == 'high':\n",
    "                speed_status = 1  \n",
    "\n",
    "                        \n",
    "\n",
    "        # return the speed, duration status and the time for which the function is executed\n",
    "        return speed_status, burn_quality_percentage \n",
    "\n",
    "\n",
    "# function to be called for generation regeneration evidence\n",
    "def regeneration_evidence_v2(COUNTRY_FLAG, OBD_data,\n",
    "                            active_regeneration_start_time, active_regeneration_end_time, \n",
    "                            burn_quality_percentage):\n",
    "    \n",
    "    \n",
    "                \n",
    "        # getting the active-regeneration duration in minutes\n",
    "        active_regeneration_duration = (active_regeneration_end_time - active_regeneration_start_time)//(60*1000)\n",
    "        \n",
    "        # corner case\n",
    "        # if active_regeneration_start_time >= active_regeneration_end_time \n",
    "        # active_regeneration_duration happens to be less that 10 minutes\n",
    "        if (active_regeneration_start_time >= active_regeneration_end_time) or (active_regeneration_duration <= 10):\n",
    "                # check the status of burn_quality\n",
    "                # if burn_quality == high  --> Set the speed status sufficient (1)\n",
    "                # else --> Set the speed status insufficient (0)\n",
    "                if burn_quality_percentage>=0.6 and burn_quality_percentage!=2:\n",
    "                        speed_status = 1\n",
    "                else:\n",
    "                        speed_status = 0        \n",
    "                return speed_status, burn_quality_percentage\n",
    "\n",
    "        \n",
    "        \n",
    "        # if FLAG is set to \"US\" use the following RPM and Speed thresholds\n",
    "        if  COUNTRY_FLAG == 'US':\n",
    "                RPM_RANGE = [800, 2000]\n",
    "                SPEED_THRESHOLD = 80\n",
    "\n",
    "        # if FLAG is set to \"IN\" use the following RPM and Speed thresholds\n",
    "        elif COUNTRY_FLAG == 'IN':\n",
    "                RPM_RANGE = [1000, 2000]\n",
    "                SPEED_THRESHOLD = 40\n",
    " \n",
    "\n",
    "        # extracting the relevant parameter-ID\n",
    "        dp_pid = 'spn_3251_avg'\n",
    "        rpm_pid = 'spn_190_avg'\n",
    "        speed_pid = 'spn_84_avg'\n",
    "        Time = []\n",
    "        dp_inst_Value = []\n",
    "        rpm_inst_Value = []\n",
    "        speed_inst_Value =[]\n",
    "        for pac_idx in range(len(OBD_data)):\n",
    "                if \"pids\" in OBD_data[pac_idx]:\n",
    "                    if len(OBD_data[pac_idx]['pids'])>0:\n",
    "                        for sub_pid_cnt in range(0,len(OBD_data[pac_idx]['pids'])):\n",
    "                                State = OBD_data[pac_idx]['pids'][sub_pid_cnt]\n",
    "                                # extracting DPFDP\n",
    "                                if dp_pid in State:\n",
    "                                        Time.append(State[dp_pid]['timestamp'])\n",
    "                                        dp_inst_Value.append(State[dp_pid]['value'][0])\n",
    "                                # extracting RPM        \n",
    "                                if rpm_pid in State:\n",
    "                                        rpm_inst_Value.append(State[rpm_pid]['value'][0])\n",
    "                                # extracting SPEED       \n",
    "                                if speed_pid in State:\n",
    "                                        speed_inst_Value.append(State[speed_pid]['value'][0])    \n",
    "\n",
    "                                             \n",
    "                                \n",
    "        # applying the RPM constraint\n",
    "        # getting the correspnding values of different varaibles after applying constraints\n",
    "        # Time1 constitutes of timestamps where the RPM conditions are met\n",
    "        dp_rpm_constrained = []\n",
    "        speed_rpm_constrained = []\n",
    "        Time1 = []\n",
    "        rpm_constrained = []\n",
    "\n",
    "        # iterating through each timestamp to make the RPM constraint check\n",
    "        for i in range(len(Time)):\n",
    "            if rpm_inst_Value[i]>=RPM_RANGE[0] and rpm_inst_Value[i]<=RPM_RANGE[-1]:\n",
    "                    dp_rpm_constrained.append(dp_inst_Value[i])\n",
    "                    Time1.append(Time[i])\n",
    "                    rpm_constrained.append(rpm_inst_Value[i])\n",
    "                    speed_rpm_constrained.append(speed_inst_Value[i])\n",
    "        \n",
    "        # after applying the rpm-constraint check which are the nearest active regeneration start and end indices\n",
    "        nearest_ar_start_idx = (np.abs(np.array(Time1) -  active_regeneration_start_time)).argmin()\n",
    "        nearest_ar_end_idx = (np.abs(np.array(Time1) -  active_regeneration_end_time)).argmin()\n",
    "        \n",
    "        # if the nearest start and end indices comes out to be same (which implies after applying the rpm-constraint we are \n",
    "        # not left with any valid point)\n",
    "        if (nearest_ar_start_idx == nearest_ar_end_idx):\n",
    "                if burn_quality_percentage>=0.6 and burn_quality_percentage!=2:\n",
    "                        speed_status = 1\n",
    "                else:\n",
    "                        speed_status = 0\n",
    "                return speed_status, burn_quality_percentage\n",
    "                \n",
    "\n",
    "\n",
    "        # calculating the mid-region of the active regeneration zone\n",
    "        mid_idx = (nearest_ar_start_idx + nearest_ar_end_idx)//2\n",
    "\n",
    "        # bringing both the pre and post window to same sizes\n",
    "        pre_start_idx = 0\n",
    "        post_end_idx = len(Time1)\n",
    "        # if length of the pre-regeneration window > length of the post-regeneration window\n",
    "        # bring the pre-window to same size as the post window\n",
    "        if (mid_idx) > (len(Time1)- nearest_ar_end_idx):\n",
    "                pre_start_idx = mid_idx - (len(Time1)- nearest_ar_end_idx)\n",
    "        # if length of the pre-regeneration window < length of the post-regeneration window  \n",
    "        # bring the post-window to same size as the pre window\n",
    "        elif (mid_idx) < (len(Time1)- nearest_ar_end_idx):\n",
    "                post_end_idx = nearest_ar_end_idx + mid_idx \n",
    "        \n",
    "        # fixing the pre_dp, pre_rpm and the pre_speed window\n",
    "        pre_dp_window = dp_rpm_constrained[pre_start_idx:mid_idx]\n",
    "        pre_rpm_window = rpm_constrained[pre_start_idx:mid_idx]\n",
    "        pre_speed_window = speed_rpm_constrained[pre_start_idx:mid_idx]\n",
    "\n",
    "        # fixing the post_dp, post_rpm and the post_speed window\n",
    "        post_dp_window = dp_rpm_constrained[nearest_ar_end_idx:post_end_idx]\n",
    "        post_rpm_window = rpm_constrained[nearest_ar_end_idx:post_end_idx]\n",
    "        post_speed_window = speed_rpm_constrained[nearest_ar_end_idx:post_end_idx]\n",
    "        \n",
    "        # quantifying the burn_quality basis the burn_quality_percentage\n",
    "        #   0 <= burn_quality_percentage < 0.33 --> low burn_quality\n",
    "        if (burn_quality_percentage>=0 and burn_quality_percentage<0.33):\n",
    "                burn_quality = 'low'\n",
    "        #   0.33 <= burn_quality_percentage < 0.66 --> medium burn_quality        \n",
    "        elif (burn_quality_percentage>=0.33 and burn_quality_percentage<0.66):\n",
    "                burn_quality = 'medium' \n",
    "        #   0.66 <= burn_quality_percentage < 1 --> high burn_quality        \n",
    "        elif (burn_quality_percentage>=0.66 and burn_quality_percentage<1):\n",
    "                burn_quality = 'high' \n",
    "        #  burn_quality_percentage == 2 --> failed burn            \n",
    "        elif burn_quality_percentage == 2:\n",
    "                burn_quality = 'failed'\n",
    "\n",
    "        # reconcilation logic for low and high burn-quality        \n",
    "        if (burn_quality == 'low') or (burn_quality == 'high'):\n",
    "            \n",
    "            # getting the partition for breaking the rpm-bins into two equal bins \n",
    "            bin_size = (RPM_RANGE[-1]-RPM_RANGE[0])//2       \n",
    "            \n",
    "        \n",
    "            pre_descriptive_statistics_all_bins = []\n",
    "            post_descriptive_statistics_all_bins = []\n",
    "            pre_rpm_bin_considered = []\n",
    "            post_rpm_bin_considered = []\n",
    "            pre_speed_bin_considered = []\n",
    "            post_speed_bin_considered = []\n",
    "\n",
    "            # getting the RPM_RANGE and creating bin on those\n",
    "            for bin in range(RPM_RANGE[0],  RPM_RANGE[-1], bin_size):\n",
    "                    # creating the low and high speed bins for each of the rpm-bins\n",
    "                    # getting the pre-bins\n",
    "                    pre_dp_in_rpm_low_speed_bin = []\n",
    "                    pre_dp_in_rpm_high_speed_bin = []\n",
    "                    # getting the post-bins\n",
    "                    post_dp_in_rpm_low_speed_bin = []\n",
    "                    post_dp_in_rpm_high_speed_bin = []\n",
    "\n",
    "\n",
    "                    # parsing through all the enteries of the dp-window\n",
    "                    for j in range(len(pre_dp_window)):  \n",
    "                            \n",
    "                            # if the rpm values are between the bin & (bin+bin_size)\n",
    "\n",
    "                            # checking the above condition for pre-rpm window\n",
    "                            if pre_rpm_window[j]>= bin and pre_rpm_window[j] < (bin+bin_size):\n",
    "                                    # getting the dp in the low-speed zone of specific rpm-zone\n",
    "                                    if int(pre_speed_window[j]) <= SPEED_THRESHOLD:\n",
    "                                            pre_dp_in_rpm_low_speed_bin.append(pre_dp_window[j])\n",
    "                                    # getting the dp in the high-speed zone of specific rpm-zone    \n",
    "                                    else:\n",
    "                                            pre_dp_in_rpm_high_speed_bin.append(pre_dp_window[j])   \n",
    "                            \n",
    "                            # checking the above condition for the post-window\n",
    "                            if post_rpm_window[j]>= bin and post_rpm_window[j] < (bin + bin_size):  \n",
    "                                    # getting the dp in the low-speed zone of specific rpm-zone\n",
    "                                    if int(post_speed_window[j]) <= SPEED_THRESHOLD:\n",
    "                                            post_dp_in_rpm_low_speed_bin.append(post_dp_window[j])\n",
    "                                    # getting the dp in the high-speed zone of specific rpm-zone    \n",
    "                                    else:\n",
    "                                            post_dp_in_rpm_high_speed_bin.append(post_dp_window[j])             \n",
    "\n",
    "                    # if rpm with lower-speed bin\n",
    "                    if len(pre_dp_in_rpm_low_speed_bin) > 0:  \n",
    "                            pre_descriptive_statistics_all_bins.append([\n",
    "                                                            len(pre_dp_in_rpm_low_speed_bin),\n",
    "                                                            np.mean(pre_dp_in_rpm_low_speed_bin) \n",
    "                                                            ]) \n",
    "                            pre_rpm_bin_considered.append((bin, (bin+bin_size)))\n",
    "                            pre_speed_bin_considered.append(\"<=\"+str(SPEED_THRESHOLD))\n",
    "                                            \n",
    "                    if len(post_dp_in_rpm_low_speed_bin) > 0: \n",
    "                            post_descriptive_statistics_all_bins.append([\n",
    "                                                             len(post_dp_in_rpm_low_speed_bin),\n",
    "                                                             np.mean(post_dp_in_rpm_low_speed_bin) \n",
    "                                                    ]) \n",
    "                            post_rpm_bin_considered.append((bin, (bin+bin_size)))\n",
    "                            post_speed_bin_considered.append(\"<=\"+str(SPEED_THRESHOLD))\n",
    "\n",
    "\n",
    "                    # if rpm with higher-speed bin                \n",
    "                    if len(pre_dp_in_rpm_high_speed_bin) > 0:\n",
    "                            pre_descriptive_statistics_all_bins.append([\n",
    "                                                            len(pre_dp_in_rpm_high_speed_bin),\n",
    "                                                            np.mean(pre_dp_in_rpm_high_speed_bin)])\n",
    "                            pre_rpm_bin_considered.append((bin, (bin+bin_size)))\n",
    "                            pre_speed_bin_considered.append(\">\"+str(SPEED_THRESHOLD))\n",
    "\n",
    "                    if len(post_dp_in_rpm_high_speed_bin) > 0:\n",
    "                            post_descriptive_statistics_all_bins.append([\n",
    "                                                                   len(post_dp_in_rpm_high_speed_bin),\n",
    "                                                                   np.mean(post_dp_in_rpm_high_speed_bin)]) \n",
    "                            post_rpm_bin_considered.append((bin, (bin+bin_size)))\n",
    "                            post_speed_bin_considered.append(\">\"+str(SPEED_THRESHOLD))   \n",
    "                                                            \n",
    "                                    \n",
    "            pre_descriptive_statistics_all_bins = np.array(pre_descriptive_statistics_all_bins)\n",
    "            post_descriptive_statistics_all_bins = np.array(post_descriptive_statistics_all_bins)\n",
    "\n",
    "            # Create a function to create a 2D array from input arrays\n",
    "            def create_2d_array(arr1, arr2, arr3):\n",
    "                return np.column_stack((arr1, arr2, arr3))\n",
    "\n",
    "            \n",
    "            if len(pre_descriptive_statistics_all_bins):\n",
    "                pre_statistics = create_2d_array(pre_rpm_bin_considered, pre_speed_bin_considered, pre_descriptive_statistics_all_bins)\n",
    "        \n",
    "            if len(post_descriptive_statistics_all_bins):\n",
    "                post_statistics = create_2d_array(post_rpm_bin_considered, post_speed_bin_considered, post_descriptive_statistics_all_bins)\n",
    "                \n",
    "\n",
    "            # Function to remove duplicates from a 2D array\n",
    "            def remove_duplicates(arr):\n",
    "                _, unique_indices = np.unique(arr, axis=0, return_index=True)\n",
    "                return arr[np.sort(unique_indices)]\n",
    "\n",
    "            # Remove duplicates from pre and post statistics arrays\n",
    "            if pre_descriptive_statistics_all_bins.size > 0:\n",
    "                pre_statistics = remove_duplicates(pre_statistics)\n",
    "\n",
    "            if post_descriptive_statistics_all_bins.size > 0:\n",
    "                post_statistics = remove_duplicates(post_statistics)\n",
    "\n",
    "\n",
    "            # Function to merge pre and post statistics arrays based on RPM and Speed bins\n",
    "            def merge_statistics(pre_arr, post_arr):\n",
    "                pre_rpm_bin = pre_arr[:, 0]\n",
    "                pre_speed_bin = pre_arr[:, 1]\n",
    "                post_rpm_bin = post_arr[:, 0]\n",
    "                post_speed_bin = post_arr[:, 1]\n",
    "\n",
    "                merged_indices = np.where((np.isin(pre_rpm_bin, post_rpm_bin)) & (np.isin(pre_speed_bin, post_speed_bin)))[0]\n",
    "                merged_pre = pre_arr[merged_indices]\n",
    "                merged_post = post_arr[merged_indices]\n",
    "\n",
    "                return np.column_stack((merged_pre, merged_post[:, 2:]))\n",
    "\n",
    "            # Merge pre and post statistics arrays\n",
    "            if pre_descriptive_statistics_all_bins.size > 0 and post_descriptive_statistics_all_bins.size > 0:\n",
    "                df_statistics = merge_statistics(pre_statistics, post_statistics)\n",
    "\n",
    "            print(\"this is the df_statistics using the version-2: \", df_statistics)     \n",
    "\n",
    "\n",
    "            # Filter out bins with counts less than 5 in either Pre or Post\n",
    "            df_statistics = df_statistics[(df_statistics[:, 2] >= 5) & (df_statistics[:, 4] >= 5)]\n",
    "\n",
    "            # Calculate fraction of good bins where Post Mean < Pre Mean\n",
    "            fraction_good_bins = np.sum(df_statistics[:, 3] < df_statistics[:, 5]) / df_statistics.shape[0]\n",
    "\n",
    "\n",
    "            print(\"these are the fraction of good-bins using the version-2: \", fraction_good_bins)\n",
    "\n",
    "    \n",
    "            # for \"high\" soot burn\n",
    "            # the logic goes something like this\n",
    "            # if 0/4 bins has the post-dp < pre-dp, classify as low\n",
    "            # if 1/4 or 2/4 has the post-dp < pre-dp, classify as medium \n",
    "            if burn_quality == 'high' and fraction_good_bins == 0:\n",
    "                    burn_quality = 'low'\n",
    "                    burn_quality_percentage = burn_quality_percentage/3\n",
    "            elif burn_quality == 'high' and fraction_good_bins <= 0.5 and fraction_good_bins != 0:\n",
    "                    burn_quality = 'medium'\n",
    "                    burn_quality_percentage = burn_quality_percentage/2   \n",
    "\n",
    "            # for \"low\" soot burn\n",
    "            # the logic goes something like this\n",
    "            # if 3/4 or 4/4 has the post-dp < pre-dp, classify as medium \n",
    "            if burn_quality == 'low' and fraction_good_bins > 0.5:\n",
    "                    burn_quality = 'medium'\n",
    "                    burn_quality_percentage = burn_quality_percentage * 2\n",
    "        high_speed_count = 0\n",
    "        # giving the duration and speed status for each of the moderate and low burn_quality\n",
    "        if burn_quality != 'high':     \n",
    "                # if for atleast 50% of the time; the vehicle is running at required speed  \n",
    "                # then set the speed status to sufficient i.e. 1        \n",
    "                for speed in speed_inst_Value:\n",
    "                        if speed >= SPEED_THRESHOLD:\n",
    "                                high_speed_count += 1\n",
    "                # if for atleast 50% of the time speed happens to be high during regeneration                \n",
    "                if high_speed_count/len(speed_inst_Value) > 0.5:    \n",
    "                        speed_status = 1\n",
    "                        \n",
    "                elif  high_speed_count/len(speed_inst_Value) <= 0.5: \n",
    "                        speed_status = 0\n",
    "        # if burn_quality is high ; keep the speed status sufficient               \n",
    "        elif burn_quality == 'high':\n",
    "                speed_status = 1  \n",
    "\n",
    "                        \n",
    "\n",
    "        # return the speed, duration status and the time for which the function is executed\n",
    "        return speed_status, burn_quality_percentage \n",
    "\n",
    "\n",
    "\n",
    "def REGENERATION_EVIDENCE_MSTR(vehicle_id, COUNTRY_FLAG, active_regeneration_start_time, active_regeneration_end_time, \n",
    "                            burn_quality_percentage, spec_obj):\n",
    "    \n",
    "        # extracting the OBD-data \n",
    "        \n",
    "        Start_TS = active_regeneration_start_time - 60*60*1000\n",
    "        End_TS = active_regeneration_end_time + 60*60*1000\n",
    "\n",
    "        #OBD_data = get_obd_data(vehicle_id, Start_TS, End_TS)\n",
    "        URL = 'https://old-data-downloader.intangles-aws-us-east-1.intangles.us/download/' + str(vehicle_id) +  \"/\" + str(Start_TS) + \"/\" + str(End_TS)\n",
    "        r = requests.get(URL,stream=True)\n",
    "        OBD_data = r.json()     \n",
    "   \n",
    "\n",
    "        \n",
    "        # if the OBD_data is not empty\n",
    "        if len(OBD_data): \n",
    "                # mapping the actual-regeneration time\n",
    "                actual_regeneration_time = active_regeneration_shift(OBD_data, active_regeneration_start_time, spec_obj)\n",
    "                speed_status, burn_quality_percentage = regeneration_evidence(COUNTRY_FLAG, OBD_data,\n",
    "                                                                active_regeneration_start_time, active_regeneration_end_time, \n",
    "                                                                burn_quality_percentage)\n",
    "        else:\n",
    "                actual_regeneration_time = active_regeneration_start_time\n",
    "                # if burn_quality is high --> speed_status should be sufficient --> 1\n",
    "                if burn_quality_percentage > 0.6:\n",
    "                        speed_status = 1\n",
    "                # if burn quality anything apart from high --> speed status should be insufficient --> 0         \n",
    "                else:\n",
    "                        speed_status = 0\n",
    "        \n",
    "\n",
    "        return speed_status, burn_quality_percentage, actual_regeneration_time \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_id = 1281011284925480960\n",
    "active_regeneration_start_time = 1715983200000\n",
    "active_regeneration_end_time = 1715986800000\n",
    "COUNTRY_FLAG = 'US'\n",
    "burn_quality_percentage = 0.2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users/Harleen.Kaur/Downloads/Spec Object\"\n",
    "\n",
    "# Open the JSON file and load its contents\n",
    "with open(file_path, \"r\") as file:\n",
    "    spec_obj = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_status, burn_quality_percentage, actual_regeneration_time = REGENERATION_EVIDENCE_MSTR(vehicle_id, COUNTRY_FLAG, active_regeneration_start_time, active_regeneration_end_time, \n",
    "                            burn_quality_percentage, spec_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burn_quality_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_id = 1281011284925480960\n",
    "Start_TS = 1715944320000 \n",
    "End_TS = 1716143340000\n",
    "URL = 'https://old-data-downloader.intangles-aws-us-east-1.intangles.us/download/' + str(vehicle_id) +  \"/\" + str(Start_TS) + \"/\" + str(End_TS)\n",
    "r = requests.get(URL,stream=True)\n",
    "print(r)\n",
    "OBD_data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_pid = 'spn_3251_avg'\n",
    "rpm_pid = 'spn_190_avg'\n",
    "speed_pid = 'spn_84_avg'\n",
    "Time = []\n",
    "dp_inst_Value = []\n",
    "rpm_inst_Value = []\n",
    "speed_inst_Value =[]\n",
    "for pac_idx in range(len(OBD_data)):\n",
    "        if \"pids\" in OBD_data[pac_idx]:\n",
    "            if len(OBD_data[pac_idx]['pids'])>0:\n",
    "                for sub_pid_cnt in range(0,len(OBD_data[pac_idx]['pids'])):\n",
    "                        State = OBD_data[pac_idx]['pids'][sub_pid_cnt]\n",
    "                        # extracting DPFDP\n",
    "                        if dp_pid in State:\n",
    "                                Time.append(State[dp_pid]['timestamp'])\n",
    "                                dp_inst_Value.append(State[dp_pid]['value'][0])\n",
    "                        # extracting RPM        \n",
    "                        if rpm_pid in State:\n",
    "                                rpm_inst_Value.append(State[rpm_pid]['value'][0])\n",
    "                        # extracting SPEED       \n",
    "                        if speed_pid in State:\n",
    "                                speed_inst_Value.append(State[speed_pid]['value'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_inst_Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx],idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RPM_Contraint(DATA,T1,RANGE):\n",
    "\n",
    "    TEMP = DATA[0,:] # 0th is RPM\n",
    "    nums = TEMP[(RANGE[0] < TEMP) & (TEMP <= RANGE[1])]\n",
    "    Samples = len(nums)\n",
    "    #print(Samples)\n",
    "    DATA_OUT = np.zeros((DATA.shape[0],Samples))\n",
    "    T_OUT = np.zeros(Samples)\n",
    "\n",
    "    out_cnt = 0\n",
    "\n",
    "    for cnt in range(0,DATA.shape[1]):\n",
    "        if ((RANGE[0] < TEMP[cnt]) and (TEMP[cnt] <= RANGE[1])):\n",
    "            for var_cnt in range(0,DATA.shape[0]):\n",
    "                DATA_OUT[var_cnt,out_cnt] = DATA[var_cnt,cnt]\n",
    "            T_OUT[out_cnt] = T1[cnt]\n",
    "            out_cnt = out_cnt + 1\n",
    "\n",
    "    return DATA_OUT,T_OUT\n",
    "    \n",
    "\n",
    "def Throttle_Contraint(DATA,T2,TH):\n",
    "\n",
    "    TEMP = DATA[2,:] # 7th is Throttle\n",
    "    nums = TEMP[(TH < TEMP)]\n",
    "    Samples = len(nums)\n",
    "    #print(Samples)\n",
    "    DATA_OUT = np.zeros((DATA.shape[0],Samples))\n",
    "    T_OUT = np.zeros(Samples)\n",
    "\n",
    "    out_cnt = 0\n",
    "\n",
    "    for cnt in range(0,DATA.shape[1]):\n",
    "        if (TH < TEMP[cnt]):\n",
    "            for var_cnt in range(0,DATA.shape[0]):\n",
    "                DATA_OUT[var_cnt,out_cnt] = DATA[var_cnt,cnt]\n",
    "            T_OUT[out_cnt] = T2[cnt]\n",
    "            out_cnt = out_cnt + 1\n",
    "\n",
    "    return DATA_OUT,T_OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_PID_data_v3(data, PROTOCOL,LABEL):\n",
    "    \n",
    "    if (PROTOCOL == 'SAE'):\n",
    "\n",
    "        if LABEL == 'IMAP':\n",
    "            PID_TAG = '106'\n",
    "        elif LABEL == 'ENGINE LOAD':\n",
    "            PID_TAG = '92'\n",
    "        elif LABEL == 'ENGINE RPM':\n",
    "            PID_TAG = '190'\n",
    "        elif LABEL == 'FUEL RATE':\n",
    "            PID_TAG = '183'\n",
    "        elif LABEL == 'MAF':\n",
    "            PID_TAG = '132'\n",
    "        elif LABEL == 'BOOST':\n",
    "            PID_TAG = '102'\n",
    "        elif LABEL == 'BAROMETER':\n",
    "            PID_TAG = '108'\n",
    "        elif LABEL == 'THROTTLE':\n",
    "            PID_TAG = '91'\n",
    "        elif LABEL == 'ATGMF': # Eaxuast Gas Flow Rate\n",
    "            PID_TAG = '3236'\n",
    "        elif LABEL == 'DPFDP': # DPF Diffrential Pressure (across DPF)\n",
    "            PID_TAG = '3251'\n",
    "        elif LABEL == 'SCRT':   # SCR Catalyst Temperature Before Catalyst (DPF out)\n",
    "            PID_TAG = '4360'\n",
    "        elif LABEL == 'SPEED': # Wheep based Vehicle Speed\n",
    "            PID_TAG = '84'\n",
    "        elif LABEL == 'DPFINT':# DPF in Temperature Before DPF (DOC out)\n",
    "            PID_TAG = '4766' #4766\n",
    "        elif LABEL == 'IS': #  regen inhibited\n",
    "            PID_TAG = '3703'        \n",
    "        elif LABEL == 'FUEL USE': #  Total fuel used (high precision)\n",
    "            PID_TAG = '5054'        \n",
    "        elif LABEL == 'DISTANCE': #  Total distance travelled (high precision)\n",
    "            PID_TAG = '917' # 245\n",
    "        elif LABEL == 'SOOTLOAD':\n",
    "            PID_TAG = '5466' # 245 #3719 generic check       \n",
    "        elif LABEL == 'ACTIVEREGEN':\n",
    "            PID_TAG = '3700' # 245\n",
    "\n",
    "    elif (PROTOCOL == 'SAE_AVG'):\n",
    "\n",
    "        if LABEL == 'IMAP':\n",
    "            PID_TAG = 'spn_106_avg'\n",
    "        elif LABEL == 'ENGINE LOAD':\n",
    "            PID_TAG = 'spn_92_avg'\n",
    "        elif LABEL == 'ENGINE RPM':\n",
    "            PID_TAG = 'spn_190_avg'\n",
    "        elif LABEL == 'FUEL RATE':\n",
    "            PID_TAG = 'spn_183_avg'\n",
    "        elif LABEL == 'MAF':\n",
    "            PID_TAG = 'spn_132_avg'\n",
    "        elif LABEL == 'BOOST':\n",
    "            PID_TAG = 'spn_102_avg'\n",
    "        elif LABEL == 'BAROMETER':\n",
    "            PID_TAG = 'spn_108_avg'\n",
    "        elif LABEL == 'THROTTLE':\n",
    "            PID_TAG = 'spn_91_avg'\n",
    "        elif LABEL == 'ATGMF': # Eaxuast Gas Flow Rate\n",
    "            PID_TAG = 'spn_3236_avg'\n",
    "        elif LABEL == 'DPFDP': # DPF Diffrential Pressure (across DPF)\n",
    "            PID_TAG = 'spn_3251_avg'\n",
    "        elif LABEL == 'SCRT':   # SCR Catalyst Temperature Before Catalyst (DPF out)\n",
    "            PID_TAG = 'spn_4360_avg'\n",
    "        elif LABEL == 'SPEED': # Wheep based Vehicle Speed\n",
    "            PID_TAG = 'spn_84_avg'\n",
    "        elif LABEL == 'DPFINT':# DPF in Temperature Before DPF (DOC out)\n",
    "            PID_TAG = 'spn_4766_avg' #4766\n",
    "        elif LABEL == 'IS': #  regen inhibited\n",
    "            PID_TAG = 'spn_3703_avg'        \n",
    "        elif LABEL == 'FUEL USE': #  Total fuel used (high precision)\n",
    "            PID_TAG = 'spn_5054_avg'        \n",
    "        elif LABEL == 'DISTANCE': #  Total distance travelled (high precision)\n",
    "            PID_TAG = 'spn_917_avg' # 245\n",
    "        elif LABEL == 'SOOTLOAD':\n",
    "            PID_TAG = 'spn_5466_avg' # 245 #3719 generic check       \n",
    "        elif LABEL == 'ACTIVEREGEN':\n",
    "            PID_TAG = 'spn_3700_avg' # 245\n",
    "        \n",
    "\n",
    "    elif(PROTOCOL == 'ISO'):\n",
    "\n",
    "        if LABEL == 'IMAP':\n",
    "            PID_TAG = '87BC'#MODIFY the \"if PID_TAG in State1:\" loop (append for loop on top)  \n",
    "        elif LABEL == 'ENGINE LOAD':\n",
    "            PID_TAG = '04'\n",
    "        elif LABEL == 'ENGINE RPM':\n",
    "            PID_TAG = '0C'\n",
    "        elif LABEL == 'FUEL RATE':\n",
    "            PID_TAG = '5E'\n",
    "        elif LABEL == 'MAF':\n",
    "            PID_TAG = '10'\n",
    "        elif LABEL == 'BOOST':\n",
    "            PID_TAG = '102'\n",
    "        elif LABEL == 'BAROMETER':\n",
    "            PID_TAG = '33'\n",
    "        elif LABEL == 'THROTTLE':\n",
    "            PID_TAG = '49'#MODIFY the \"if PID_TAG in State1:\" loop (append for loop on top)\n",
    "        elif LABEL == 'DPFDP': # DPF Diffrential Pressure (across DPF)\n",
    "            PID_TAG = '7A'\n",
    "    Time_vec = []\n",
    "    Val_vec = []\n",
    "\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        if \"pids\" in data[i]:\n",
    "            if len(data[i]['pids'])>0:\n",
    "                for sub_pid_cnt in range(0,len(data[i]['pids'])):\n",
    "                    State = data[i]['pids'][sub_pid_cnt]\n",
    "                    if PID_TAG in State:\n",
    "                        Time_vec.append(State[PID_TAG]['timestamp'])\n",
    "                        Val_vec.append(State[PID_TAG]['value'][0])\n",
    "      \n",
    "                \n",
    "    return Time_vec,Val_vec        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regeneration_evidence_v3(vehicle_id, FLAG,\n",
    "                            active_regeneration_start_time, active_regeneration_end_time, \n",
    "                            burn_quality_percentage, Median_Duration):\n",
    "    \n",
    "    \n",
    "        if active_regeneration_start_time >= active_regeneration_end_time:\n",
    "            duration_status = \"Invalid Start and End Time\"\n",
    "            speed_status =\"NA\"\n",
    "            return speed_status, duration_status, burn_quality_percentage\n",
    "\n",
    "        # getting the active-regeneration duration\n",
    "        active_regeneration_duration = (active_regeneration_end_time - active_regeneration_start_time)//(60*1000)\n",
    "\n",
    "        print(\"this is the active-Regeneration Duration: \", active_regeneration_duration)\n",
    "\n",
    "        # if the duration of active-regeneration is less than 10 minutes \n",
    "        if active_regeneration_duration <= 10:\n",
    "                        duration_status = \"insufficient\"\n",
    "                        speed_status =\"NA\"\n",
    "                        return speed_status, duration_status, burn_quality_percentage\n",
    "        \n",
    "        # defining the intial and final time stamps needed for creating pre and post regeneration windows\n",
    "        # We are selecting the time which is 1 hour before the start of the active-regeneration event\n",
    "        # and 1 hour after the ative-regeneration event\n",
    "        Start_TS = active_regeneration_start_time - 1*60*60*1000\n",
    "        End_TS = active_regeneration_end_time + 1*60*60*1000\n",
    "\n",
    "       \n",
    "        \n",
    "        # if FLAG is set to \"US\", use the US URL link\n",
    "        if FLAG == 'US':\n",
    "                \n",
    "                RPM_RANGE = [800, 2000]\n",
    "                SPEED_THRESHOLD = 80\n",
    "\n",
    "                # loading the OBD_data\n",
    "                URL = 'https://old-data-downloader.intangles-aws-us-east-1.intangles.us/download/' + str(vehicle_id) +  \"/\" + str(Start_TS) + \"/\" + str(End_TS)\n",
    "                \n",
    "        # if FLAG is set to \"IN\", use the Indian URL link\n",
    "        elif FLAG == 'IN':\n",
    "                \n",
    "                RPM_RANGE = [1000, 2000]\n",
    "                SPEED_THRESHOLD = 40\n",
    "\n",
    "                # loading the OBD_data\n",
    "                URL = 'http://data-download.intangles.com:1883/download/' + str(vehicle_id) +  \"/\" + str(Start_TS) + \"/\" + str(End_TS)\n",
    "                \n",
    "\n",
    "        # getting the OBD data between start and end period\n",
    "        r = requests.get(URL,stream=True)\n",
    "        OBD_data = r.json()            \n",
    "        \n",
    "        # extracting the relevant parameter-ID\n",
    "        # extracting the variable Differential Pressure\n",
    "        Time, dp_inst_Value = extract_PID_data_v3(OBD_data, 'SAE_AVG', 'DPFDP')\n",
    "        # extracting the varible Engine RPM\n",
    "        Time, rpm_inst_Value = extract_PID_data_v3(OBD_data, 'SAE_AVG', 'ENGINE RPM')\n",
    "        # extracting the variable SPEED\n",
    "        Time, speed_inst_Value = extract_PID_data_v3(OBD_data, 'SAE_AVG', 'SPEED')\n",
    "\n",
    "\n",
    "        print(Time)\n",
    "        \n",
    "       \n",
    "\n",
    "        # applying the RPM constraint\n",
    "        # getting the correspnding values of different varaibles after applying constraint\n",
    "        # Time1 constitutes of timestamps where the RPM conditions are met\n",
    "        dp_rpm_constrained = []\n",
    "        speed_rpm_constrained = []\n",
    "        Time1 = []\n",
    "        rpm_constrained = []\n",
    "\n",
    "        # iterating through each timestamp to make the RPM constraint check\n",
    "        for i in range(len(Time)):\n",
    "                if rpm_inst_Value[i]>=RPM_RANGE[0] and rpm_inst_Value[i]<=RPM_RANGE[-1]:\n",
    "                        dp_rpm_constrained.append(dp_inst_Value[i])\n",
    "                        Time1.append(Time[i])\n",
    "                        rpm_constrained.append(rpm_inst_Value[i])\n",
    "                        speed_rpm_constrained.append(speed_inst_Value[i])\n",
    "        \n",
    "        # after applying the rpm-constraint check which are the nearest active regeneration start and end indices\n",
    "        nearest_ar_start_idx = (np.abs(np.array(Time1) -  active_regeneration_start_time)).argmin()\n",
    "        nearest_ar_end_idx = np.abs(np.array(Time1) -  active_regeneration_end_time).argmin()\n",
    "        \n",
    "        # if the nearest start and end indices comes out to be same (which implies after applying the rpm-constrint we are not left with any valid variable points)\n",
    "        if (nearest_ar_start_idx == nearest_ar_end_idx):\n",
    "                duration_status = \"insufficient\"\n",
    "                speed_status =\"NA\"\n",
    "                return speed_status, duration_status, burn_quality_percentage\n",
    "                \n",
    "\n",
    "\n",
    "        # calculating the mid-region of the active regeneration zone\n",
    "        mid_idx = (nearest_ar_start_idx + nearest_ar_end_idx)//2\n",
    "       \n",
    "        # bringing both the pre and post window to same sizes\n",
    "        pre_start_idx = 0\n",
    "        post_end_idx = len(Time1)\n",
    "        # if length of the pre-regeneration window > length of the post-regeneration window\n",
    "        # bring the pre-window to same size as the post window\n",
    "        if (mid_idx) > (len(Time1)- nearest_ar_end_idx):\n",
    "            pre_start_idx = mid_idx - (len(Time1)- nearest_ar_end_idx)\n",
    "        # if length of the pre-regeneration window < length of the post-regeneration window  \n",
    "        # bring the post-window to same size as the pre window\n",
    "        elif   (mid_idx) < (len(Time1)- nearest_ar_end_idx):\n",
    "                post_end_idx = nearest_ar_end_idx + mid_idx  \n",
    "\n",
    "\n",
    "        # fixing the pre_dp; pre_rpm and the pre_speed window\n",
    "        pre_dp_window = dp_rpm_constrained[pre_start_idx:mid_idx]\n",
    "        pre_rpm_window = rpm_constrained[pre_start_idx:mid_idx]\n",
    "        pre_speed_window = speed_rpm_constrained[pre_start_idx:mid_idx]\n",
    "\n",
    "        # fixing the post_dp; post_rpm and the post_speed window\n",
    "        post_dp_window = dp_rpm_constrained[nearest_ar_end_idx:post_end_idx]\n",
    "        post_rpm_window = rpm_constrained[nearest_ar_end_idx:post_end_idx]\n",
    "        post_speed_window = speed_rpm_constrained[nearest_ar_end_idx:post_end_idx]\n",
    "\n",
    "        \n",
    "        # quantifiying the burn_quality basis the burn_quality_percentage\n",
    "        #   0 <= burn_quality_percentage < 0.33 --> low burn_quality\n",
    "        if (burn_quality_percentage>=0 and burn_quality_percentage<0.33):\n",
    "                burn_quality = 'low'\n",
    "        #   0.33 <= burn_quality_percentage < 0.66 --> medium burn_quality        \n",
    "        elif (burn_quality_percentage>=0.33 and burn_quality_percentage<0.66):\n",
    "                burn_quality = 'medium' \n",
    "        #   0.66 <= burn_quality_percentage < 1 --> high burn_quality        \n",
    "        elif (burn_quality_percentage>=0.66 and burn_quality_percentage<1):\n",
    "                burn_quality = 'high' \n",
    "         #  burn_quality_percentage == 2 --> failed burn            \n",
    "        elif burn_quality_percentage == 2:\n",
    "                burn_quality = 'failed'\n",
    "\n",
    "        # reconcilation logic for low and high burn-quality        \n",
    "        if (burn_quality == 'low') or (burn_quality == 'high'):\n",
    "                        \n",
    "                        \n",
    "                        # getting the partition for breaking the rpm-bins into two euqla bins \n",
    "                        bin_size = (RPM_RANGE[-1]-RPM_RANGE[0])//2       \n",
    "                        # getting the columns (we area capturing the count and mean of the dp values in ecah of the rpm-bins)\n",
    "                        columns = [\n",
    "                                'RPM Bin', 'Speed Bin', 'Count', \n",
    "                                'Mean'\n",
    "                                ]\n",
    "\n",
    "                        # capturing the decriptive statistics, and their corresponding rpm and speed bin\n",
    "                        df_pre_statistics_all_vehicles = pd.DataFrame(columns = columns)\n",
    "                        df_post_statistics_all_vehicles = pd.DataFrame(columns = columns)\n",
    "\n",
    "                        pre_descriptive_statistics_all_bins = []\n",
    "                        post_descriptive_statistics_all_bins = []\n",
    "                        pre_rpm_bin_considered = []\n",
    "                        post_rpm_bin_considered = []\n",
    "                        pre_speed_bin_considered = []\n",
    "                        post_speed_bin_considered = []\n",
    "\n",
    "                        \n",
    "                        print(\"this is the RPM Range: \", RPM_RANGE)\n",
    "\n",
    "                        # getting the RPM_RANGE and creating bin-on those\n",
    "                        for bin in range(RPM_RANGE[0],  RPM_RANGE[-1], bin_size):\n",
    "                                # creating the low and high speed bins for each of the rpm-bins\n",
    "                                # getting the pre-bins\n",
    "                                pre_dp_in_rpm_low_speed_bin = []\n",
    "                                pre_dp_in_rpm_high_speed_bin = []\n",
    "                                # getting the post-bins\n",
    "                                post_dp_in_rpm_low_speed_bin = []\n",
    "                                post_dp_in_rpm_high_speed_bin = []\n",
    "\n",
    "\n",
    "                                # parsing through all the enteries of the dp-window\n",
    "                                for j in range(len(pre_dp_window)):  \n",
    "                                        # if the rpm values are between the bin & (bin+bin_size)\n",
    "\n",
    "                                        # checking the above condition for pre-rpm window\n",
    "                                        if pre_rpm_window[j]>= bin and pre_rpm_window[j] < (bin+bin_size):\n",
    "                                                # getting the dp in the low-speed zone of specific rpm-zone\n",
    "                                                if int(pre_speed_window[j]) <= SPEED_THRESHOLD:\n",
    "                                                        pre_dp_in_rpm_low_speed_bin.append(pre_dp_window[j])\n",
    "                                                # getting the dp in the high-speed zone of specific rpm-zone    \n",
    "                                                else:\n",
    "                                                        pre_dp_in_rpm_high_speed_bin.append(pre_dp_window[j])   \n",
    "                                        \n",
    "                                        # checking the above condition for the post-window\n",
    "                                        if post_rpm_window[j]>= bin and post_rpm_window[j] < (bin + bin_size):  \n",
    "                                        # getting the dp in the low-speed zone of specific rpm-zone\n",
    "                                                if int(post_speed_window[j]) <= SPEED_THRESHOLD:\n",
    "                                                        post_dp_in_rpm_low_speed_bin.append(post_dp_window[j])\n",
    "                                                # getting the dp in the high-speed zone of specific rpm-zone    \n",
    "                                                else:\n",
    "                                                        post_dp_in_rpm_high_speed_bin.append(post_dp_window[j])             \n",
    "\n",
    "                                # if rpm with lower-speed bin\n",
    "                                if len(pre_dp_in_rpm_low_speed_bin) > 0:\n",
    "                                        summary_statistics =  pd.DataFrame(pre_dp_in_rpm_low_speed_bin).describe()  \n",
    "                                        pre_descriptive_statistics_all_bins.append([\n",
    "                                                                        summary_statistics.loc['count'][0],\n",
    "                                                                        summary_statistics.loc['mean'][0], \n",
    "                                                                        ]) \n",
    "                                        pre_rpm_bin_considered.append((bin, (bin+bin_size)))\n",
    "                                        pre_speed_bin_considered.append(\"<=\"+str(SPEED_THRESHOLD))\n",
    "                                                        \n",
    "                                if len(post_dp_in_rpm_low_speed_bin) > 0:\n",
    "                                        summary_statistics =  pd.DataFrame(post_dp_in_rpm_low_speed_bin).describe()  \n",
    "                                        post_descriptive_statistics_all_bins.append([\n",
    "                                                                        summary_statistics.loc['count'][0],\n",
    "                                                                        summary_statistics.loc['mean'][0], \n",
    "                                                                       ]) \n",
    "                                        post_rpm_bin_considered.append((bin, (bin+bin_size)))\n",
    "                                        post_speed_bin_considered.append(\"<=\"+str(SPEED_THRESHOLD))\n",
    "\n",
    "\n",
    "                                # if rpm with higher-speed bin                \n",
    "                                if len(pre_dp_in_rpm_high_speed_bin) > 0:\n",
    "                                        summary_statistics =  pd.DataFrame(pre_dp_in_rpm_high_speed_bin).describe()  \n",
    "                                        pre_descriptive_statistics_all_bins.append([\n",
    "                                                                        summary_statistics.loc['count'][0],\n",
    "                                                                        summary_statistics.loc['mean'][0]]) \n",
    "                                        pre_rpm_bin_considered.append((bin, (bin+bin_size)))\n",
    "                                        pre_speed_bin_considered.append(\">\"+str(SPEED_THRESHOLD))\n",
    "\n",
    "                                if len(post_dp_in_rpm_high_speed_bin) > 0:\n",
    "                                        summary_statistics =  pd.DataFrame(post_dp_in_rpm_high_speed_bin).describe()  \n",
    "                                        post_descriptive_statistics_all_bins.append([\n",
    "                                                                                summary_statistics.loc['count'][0],\n",
    "                                                                                summary_statistics.loc['mean'][0]]) \n",
    "                                        post_rpm_bin_considered.append((bin, (bin+bin_size)))\n",
    "                                        post_speed_bin_considered.append(\">\"+str(SPEED_THRESHOLD))   \n",
    "                                                                          \n",
    "                                                \n",
    "                        if len(pre_descriptive_statistics_all_bins):\n",
    "                                        for j in range(len(pre_descriptive_statistics_all_bins)):  \n",
    "                                                pre_row_data = []\n",
    "                                                pre_row_data.append(pre_rpm_bin_considered[j]) #'RPM Bin'\n",
    "                                                pre_row_data.append(pre_speed_bin_considered[j]) #'Speed Bin'\n",
    "                                                pre_row_data.extend(pre_descriptive_statistics_all_bins[j]) \n",
    "                                                df_pre_statistics_all_vehicles.loc[len(df_pre_statistics_all_vehicles)] = pre_row_data\n",
    "                                \n",
    "                        if len(post_descriptive_statistics_all_bins):\n",
    "                                        for j in range(len(post_descriptive_statistics_all_bins)):\n",
    "                                                post_row_data = []  \n",
    "                                                post_row_data.append(post_rpm_bin_considered[j]) #'RPM Bin'\n",
    "                                                post_row_data.append(post_speed_bin_considered[j]) #'Speed Bin'\n",
    "                                                post_row_data.extend(post_descriptive_statistics_all_bins[j]) \n",
    "                                                df_post_statistics_all_vehicles.loc[len(df_post_statistics_all_vehicles)] = post_row_data\n",
    "\n",
    "                        # dropping off duplicates from pre and post dataframe\n",
    "                        df_pre_statistics_all_vehicles = df_pre_statistics_all_vehicles.drop_duplicates()\n",
    "                        df_post_statistics_all_vehicles = df_post_statistics_all_vehicles.drop_duplicates()\n",
    "\n",
    "                        # renaming the columns for pre and post statistical dataframes\n",
    "                        df_pre_statistics_all_vehicles.columns = [\"Pre RPM Bin\", \"Pre Speed Bin\", \n",
    "                                                                \"Pre Count\", \"Pre Mean\"]\n",
    "                                \n",
    "                        df_post_statistics_all_vehicles.columns = [\"Post RPM Bin\", \"Post Speed Bin\", \n",
    "                                                                \"Post Count\", \"Post Mean\"]\n",
    "                                \n",
    "                        # combining pre and post dataframes basis RPM and SPEED bin values \n",
    "                        df_statistics = pd.merge(df_pre_statistics_all_vehicles, df_post_statistics_all_vehicles, how='inner', \n",
    "                                                left_on=[\"Pre RPM Bin\", \"Pre Speed Bin\"],\n",
    "                                                right_on = [\"Post RPM Bin\", \"Post Speed Bin\"])\n",
    "                                \n",
    "                        # In case any duplicates generated while combining the two dataframes drop them\n",
    "                        df_statistics = df_statistics.drop_duplicates()\n",
    "\n",
    "                        # dropping all those statistical bins wherein the Pre or Post Count of values are less than 5\n",
    "                        indices_remove = df_statistics[(df_statistics['Pre Count']<5) | (df_statistics['Post Count']<5)].index\n",
    "                        df_statistics.drop(indices_remove, inplace=True)\n",
    "                                \n",
    "                        \n",
    "\n",
    "                        print(\"Below given is the statistical DataFrame: \")\n",
    "\n",
    "                        print(df_statistics)\n",
    "\n",
    "                        fraction_good_bins = df_statistics[(df_statistics[\"Post Mean\"]<df_statistics[\"Pre Mean\"])].shape[0]/df_statistics.shape[0]\n",
    "\n",
    "                                \n",
    "                        print(\"fraction of good bins: \", fraction_good_bins)\n",
    "                        # for \"high\" soot burn\n",
    "                        # the logic goes something like this\n",
    "                        # if 0/4 bins has the post-dp < pre-dp, classify as low\n",
    "                        # if 1/4 or 2/4 has the post-dp < pre-dp, classify as medium \n",
    "                        if burn_quality == 'high' and fraction_good_bins == 0:\n",
    "                                burn_quality = 'low'\n",
    "                                burn_quality_percentage = burn_quality_percentage/3\n",
    "                        elif burn_quality == 'high' and fraction_good_bins <= 0.5 and fraction_good_bins != 0:\n",
    "                                burn_quality = 'medium'\n",
    "                                burn_quality_percentage = burn_quality_percentage/2   \n",
    "\n",
    "                        # for \"low\" soot burn\n",
    "                        # the logic goes something like this\n",
    "                        # if 3/4 or 4/4 has the post-dp < pre-dp, classify as medium \n",
    "                        if burn_quality == 'low' and fraction_good_bins > 0.5:\n",
    "                                burn_quality = 'medium'\n",
    "                                burn_quality_percentage = burn_quality_percentage * 2\n",
    "        high_speed_count = 0\n",
    "        # giving the duration and speed status for ecah of the moderate and low burn_quality\n",
    "        if burn_quality != 'high':\n",
    "                # if 10 < active_regeneration_duration < Median Duration  --- > Active-Regeneration happened for sufficient duration\n",
    "                if  active_regeneration_duration>10 and active_regeneration_duration<Median_Duration:\n",
    "                        duration_status = 'moderate'\n",
    "                elif  active_regeneration_duration>Median_Duration:\n",
    "                        duration_status = 'sufficient'       \n",
    "                # if for atleast for 50% of time; the vehicle is running at required speed for sufficient amount of time         \n",
    "                for speed in speed_inst_Value:\n",
    "                        if speed >= SPEED_THRESHOLD:\n",
    "                                high_speed_count += 1\n",
    "                if high_speed_count/len(speed_inst_Value) > 0.5:    \n",
    "                        speed_status = 'sufficient'\n",
    "                        \n",
    "                elif  high_speed_count/len(speed_inst_Value) <= 0.5: \n",
    "                        speed_status = 'insufficient'\n",
    "        # if burn_quality is high ; keep the speed and duration status as NA                \n",
    "        elif burn_quality == 'high':\n",
    "                speed_status = 'NA'  \n",
    "                duration_status = 'NA' \n",
    "\n",
    "                           \n",
    "\n",
    "        # return the speed, duration status and the time for which the function is executed\n",
    "        return speed_status, duration_status, burn_quality_percentage              \n",
    "                            \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playing Ground Starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for i in range(2000):\n",
    "    print(i)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"the start time is: \", start_time)\n",
    "print(\"the end time is: \", end_time)\n",
    "print(\"the time required to run the function is: \", (end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5th May, 08:27 AM  to 5th May, 08:58 AM  'High'\n",
    "# 3rd May, 08:12 AM to 3rd May, 08:25 AM 'High'\n",
    "# 3rd May, 07:50 AM to 3rd May, 08:07 AM 'High'\n",
    "# 3rd May, 07:47 AM to 3rd May, 07:49 AM 'Failed'\n",
    "# 2nd May, 06:12 PM to 2nd May, 06:30 PM 'High'\n",
    "# 28th Apr, 07:07 AM to 28th Apr, 07:30 AM  'High'\n",
    "\n",
    "#AR_start_time = [1714877820000, 1714704120000, 1714702800000, 1714702620000, 1714653720000, 1714268220000]  \n",
    "#AR_end_time = [1714879680000,1714704900000, 1714703820000, 1714703400000, 1714654800000, 1714269600000]\n",
    "#BURN_QUALITY = ['High', 'High', 'High', 'Failed', 'Low', 'High']\n",
    "#BURN_QUALITY_PERCENTAGE = [0.98, 0.7, 0.85, 2, 0.2, 0.67]\n",
    "\n",
    "AR_start_time = 1715970600000\n",
    "AR_end_time = 1716057000000\n",
    "BURN_QUALITY_PERCENTAGE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_id = 1281011284925480960\n",
    "FLAG = 'US'\n",
    "active_regeneration_start_time = AR_start_time\n",
    "active_regeneration_end_time = AR_end_time\n",
    "burn_quality_percentage = 0.78\n",
    "Median_Duration = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Start_TS = active_regeneration_start_time\n",
    "End_TS = active_regeneration_end_time\n",
    "\n",
    "URL = 'https://old-data-downloader.intangles-aws-us-east-1.intangles.us/download/' + str(vehicle_id) +  \"/\" + str(Start_TS) + \"/\" + str(End_TS)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(URL,stream=True)\n",
    "OBD_data = r.json() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_status, duration_status, burn_quality_percentage = regeneration_evidence_v3(vehicle_id, FLAG,\n",
    "                                        active_regeneration_start_time, active_regeneration_end_time, \n",
    "                                        burn_quality_percentage, Median_Duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(speed_status)\n",
    "print(duration_status)\n",
    "print(burn_quality_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval_ls = []\n",
    "\n",
    "ts = AR_start_time\n",
    "for i in range(100):\n",
    "    vehicle_id = 1231762781519216640\n",
    "    FLAG = 'US'\n",
    "    active_regeneration_start_time = AR_start_time + i*1000\n",
    "    active_regeneration_end_time = AR_end_time + i*1000\n",
    "    burn_quality_percentage = BURN_QUALITY_PERCENTAGE\n",
    "    Median_Duration = 15\n",
    "    speed_status, duration_status, time_interval= regeneration_evidence_v3(vehicle_id, FLAG,\n",
    "                                        active_regeneration_start_time, active_regeneration_end_time, \n",
    "                                        burn_quality_percentage, Median_Duration)\n",
    "    time_interval_ls.append(time_interval)\n",
    "    print(i, \" iteration complete\")\n",
    "    print(\"tim taken in \", i , \" iteration is: \", time_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_avg = 0\n",
    "for time in time_interval_ls:\n",
    "    time_avg += time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_avg/len(time_interval_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(time_interval_ls).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Create a boxplot using Plotly Express\n",
    "fig = px.box(x=time_interval_ls)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(speed_status)\n",
    "print(duration_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pre_dp_window))\n",
    "print(len(post_dp_window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(pre_dp_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(post_dp_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regeneration_evidence_v3(vehicle_id, FLAG,\n",
    "                                        active_regeneration_start_time, active_regeneration_end_time, \n",
    "                                        burn_quality_percentage, Median_Duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playing Ground Ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_status, duration_status= regeneration_evidence_v3(vehicle_id, FLAG,\n",
    "                                                        active_regeneration_start_time, active_regeneration_end_time, \n",
    "                                                        burn_quality_percentage, Median_Duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regeneration_evidence_v2(pre_dp_window, post_dp_window, \n",
    "                          pre_rpm_window, post_rpm_window,\n",
    "                          pre_speed_window, post_speed_window,\n",
    "                          SPEED_THRESHOLD, RPM_RANGE, burn_quality,\n",
    "                          burn_quality_percentage,\n",
    "                          start_timestamp, end_timestamp):\n",
    "        \n",
    "        \n",
    "        \n",
    "        # getting the active-regeneration duration\n",
    "        active_regeneration_duration = (end_timestamp - start_timestamp)//(60*1000)\n",
    "       \n",
    "        # if the duration of active-regeneration is less than 5 minutes \n",
    "        if active_regeneration_duration < 5:\n",
    "                evidence = \"Insufficient duration\"\n",
    "        # if number of samples for quantification are insuffiecient        \n",
    "        elif burn_quality == 'NA':\n",
    "                evidence = \"Insufficient evidence\"        \n",
    "        # if burn-quality is either low or high        \n",
    "        else:\n",
    "                # if burn quality is either low or high\n",
    "                if burn_quality == 'low' or burn_quality == 'high':\n",
    "                        # getting the relevant bin-size & window-size  \n",
    "                        bin_size = (RPM_RANGE[-1]-RPM_RANGE[0])//2       \n",
    "                        # getting the columns\n",
    "                        columns = [\n",
    "                                'RPM Bin', 'Speed Bin', 'Count', \n",
    "                                'Mean', 'Standard Deviation', 'Minimum',\n",
    "                                '25th Percentile', '50th Percentile',\n",
    "                                '75th Percentile', 'Maximum'\n",
    "                                ]\n",
    "\n",
    "                        # capturing the decriptive statistics, and their corresponsding rpm and speed bin\n",
    "                        df_pre_statistics_all_vehicles = pd.DataFrame(columns = columns)\n",
    "                        df_post_statistics_all_vehicles = pd.DataFrame(columns = columns)\n",
    "\n",
    "                        pre_descriptive_statistics_all_bins = []\n",
    "                        post_descriptive_statistics_all_bins = []\n",
    "                        pre_rpm_bin_considered = []\n",
    "                        post_rpm_bin_considered = []\n",
    "                        pre_speed_bin_considered = []\n",
    "                        post_speed_bin_considered = []\n",
    "\n",
    "\n",
    "                        # getting the RPM_RANGE and creating bin-on those\n",
    "                        for bin in range(RPM_RANGE[0],  RPM_RANGE[-1], bin_size):\n",
    "                                # creating the low and high speed bins for each of the rpm-bins\n",
    "                                # getting the pre-bins\n",
    "                                pre_dp_in_rpm_low_speed_bin = []\n",
    "                                pre_dp_in_rpm_high_speed_bin = []\n",
    "                                # getting the post-bins\n",
    "                                post_dp_in_rpm_low_speed_bin = []\n",
    "                                post_dp_in_rpm_high_speed_bin = []\n",
    "\n",
    "\n",
    "                                # parsing through all the enteries of the dp-window\n",
    "                                for j in range(len(pre_dp_window)):  \n",
    "                                        # if the rpm values are between the bin & (bin+bin_size)\n",
    "\n",
    "                                        # checking the above condition for pre-rpm window\n",
    "                                        if pre_rpm_window[j]>= bin and pre_rpm_window[j] < (bin+bin_size):\n",
    "                                                # getting the dp in the low-speed zone of specific rpm-zone\n",
    "                                                if int(pre_speed_window[j]) <= SPEED_THRESHOLD:\n",
    "                                                        pre_dp_in_rpm_low_speed_bin.append(pre_dp_window[j])\n",
    "                                                # getting the dp in the high-speed zone of specific rpm-zone    \n",
    "                                                else:\n",
    "                                                    pre_dp_in_rpm_high_speed_bin.append(pre_dp_window[j])   \n",
    "                                        \n",
    "                                        # checking the above condition for the post-window\n",
    "                                        if post_rpm_window[j]>= bin and post_rpm_window[j] < (bin + bin_size):  \n",
    "                                        # getting the dp in the low-speed zone of specific rpm-zone\n",
    "                                                if int(post_speed_window[j]) <= SPEED_THRESHOLD:\n",
    "                                                        post_dp_in_rpm_low_speed_bin.append(post_dp_window[j])\n",
    "                                                # getting the dp in the high-speed zone of specific rpm-zone    \n",
    "                                                else:\n",
    "                                                        post_dp_in_rpm_high_speed_bin.append(post_dp_window[j])             \n",
    "\n",
    "                                # if rpm with lower-speed bin\n",
    "                                if len(pre_dp_in_rpm_low_speed_bin) > 0:\n",
    "                                        summary_statistics =  pd.DataFrame(pre_dp_in_rpm_low_speed_bin).describe()  \n",
    "                                        pre_descriptive_statistics_all_bins.append([\n",
    "                                                                        summary_statistics.loc['count'][0],\n",
    "                                                                        summary_statistics.loc['mean'][0], \n",
    "                                                                        summary_statistics.loc['std'][0], \n",
    "                                                                        summary_statistics.loc['min'][0], \n",
    "                                                                        summary_statistics.loc['25%'][0],\n",
    "                                                                        summary_statistics.loc['50%'][0], \n",
    "                                                                        summary_statistics.loc['75%'][0],\n",
    "                                                                        summary_statistics.loc['max'][0]]) \n",
    "                                        pre_rpm_bin_considered.append((bin, (bin+bin_size)))\n",
    "                                        pre_speed_bin_considered.append(\"<=\"+str(SPEED_THRESHOLD))\n",
    "                                        \n",
    "                                if len(post_dp_in_rpm_low_speed_bin) > 0:\n",
    "                                        summary_statistics =  pd.DataFrame(post_dp_in_rpm_low_speed_bin).describe()  \n",
    "                                        post_descriptive_statistics_all_bins.append([\n",
    "                                                                        summary_statistics.loc['count'][0],\n",
    "                                                                        summary_statistics.loc['mean'][0], \n",
    "                                                                        summary_statistics.loc['std'][0], \n",
    "                                                                        summary_statistics.loc['min'][0], \n",
    "                                                                        summary_statistics.loc['25%'][0],\n",
    "                                                                        summary_statistics.loc['50%'][0], \n",
    "                                                                        summary_statistics.loc['75%'][0],\n",
    "                                                                        summary_statistics.loc['max'][0]]) \n",
    "                                        post_rpm_bin_considered.append((bin, (bin+bin_size)))\n",
    "                                        post_speed_bin_considered.append(\"<=\"+str(SPEED_THRESHOLD))\n",
    "\n",
    "\n",
    "                                # if rpm with higher-speed bin                \n",
    "                                if len(pre_dp_in_rpm_high_speed_bin) > 0:\n",
    "                                        summary_statistics =  pd.DataFrame(pre_dp_in_rpm_high_speed_bin).describe()  \n",
    "                                        pre_descriptive_statistics_all_bins.append([\n",
    "                                                                        summary_statistics.loc['count'][0],\n",
    "                                                                        summary_statistics.loc['mean'][0],\n",
    "                                                                        summary_statistics.loc['std'][0], \n",
    "                                                                        summary_statistics.loc['min'][0], \n",
    "                                                                        summary_statistics.loc['25%'][0],\n",
    "                                                                        summary_statistics.loc['50%'][0], \n",
    "                                                                        summary_statistics.loc['75%'][0],\n",
    "                                                                        summary_statistics.loc['max'][0]]) \n",
    "                                        pre_rpm_bin_considered.append((bin, (bin+bin_size)))\n",
    "                                        pre_speed_bin_considered.append(\">\"+str(SPEED_THRESHOLD))\n",
    "\n",
    "                                if len(post_dp_in_rpm_high_speed_bin) > 0:\n",
    "                                        summary_statistics =  pd.DataFrame(post_dp_in_rpm_high_speed_bin).describe()  \n",
    "                                        post_descriptive_statistics_all_bins.append([\n",
    "                                                                                summary_statistics.loc['count'][0],\n",
    "                                                                                summary_statistics.loc['mean'][0],\n",
    "                                                                                summary_statistics.loc['std'][0], \n",
    "                                                                                summary_statistics.loc['min'][0], \n",
    "                                                                                summary_statistics.loc['25%'][0],\n",
    "                                                                                summary_statistics.loc['50%'][0], \n",
    "                                                                                summary_statistics.loc['75%'][0],\n",
    "                                                                                summary_statistics.loc['max'][0]]) \n",
    "                                        post_rpm_bin_considered.append((bin, (bin+bin_size)))\n",
    "                                        post_speed_bin_considered.append(\">\"+str(SPEED_THRESHOLD))        \n",
    "                                                \n",
    "                                        \n",
    "                        if len(pre_descriptive_statistics_all_bins):\n",
    "                                        for j in range(len(pre_descriptive_statistics_all_bins)):  \n",
    "                                                pre_row_data = []\n",
    "                                                pre_row_data.append(pre_rpm_bin_considered[j]) #'RPM Bin'\n",
    "                                                pre_row_data.append(pre_speed_bin_considered[j]) #'Speed Bin'\n",
    "                                                pre_row_data.extend(pre_descriptive_statistics_all_bins[j]) \n",
    "                                        \n",
    "                                                df_pre_statistics_all_vehicles.loc[len(df_pre_statistics_all_vehicles)] = pre_row_data\n",
    "                                \n",
    "                        if len(post_descriptive_statistics_all_bins):\n",
    "                                        for j in range(len(post_descriptive_statistics_all_bins)):\n",
    "                                                post_row_data = []  \n",
    "                                                post_row_data.append(post_rpm_bin_considered[j]) #'RPM Bin'\n",
    "                                                post_row_data.append(post_speed_bin_considered[j]) #'Speed Bin'\n",
    "                                                post_row_data.extend(post_descriptive_statistics_all_bins[j]) \n",
    "                                                df_post_statistics_all_vehicles.loc[len(df_post_statistics_all_vehicles)] = post_row_data\n",
    "\n",
    "                        df_pre_statistics_all_vehicles = df_pre_statistics_all_vehicles.drop_duplicates()\n",
    "                        df_post_statistics_all_vehicles = df_post_statistics_all_vehicles.drop_duplicates()\n",
    "\n",
    "\n",
    "                        print(df_pre_statistics_all_vehicles)\n",
    "\n",
    "\n",
    "\n",
    "                        df_pre_statistics_all_vehicles.columns = [\"Pre RPM Bin\", \"Pre Speed Bin\", \n",
    "                                                                \"Pre Count\", \"Pre Mean\", \n",
    "                                                                \"Pre Standard Deviation\", \"Pre Minimum\",\n",
    "                                                                \"Pre 25th Percentile\", \"Pre 50th Percentile\",\n",
    "                                                                \"Pre 75th Percentile\", \"Pre Maximum\"]\n",
    "                        \n",
    "                        df_post_statistics_all_vehicles.columns = [\"Post RPM Bin\", \"Post Speed Bin\", \n",
    "                                                                \"Post Count\", \"Post Mean\", \n",
    "                                                                \"Post Standard Deviation\", \"Post Minimum\",\n",
    "                                                                \"Post 25th Percentile\", \"Post 50th Percentile\",\n",
    "                                                                \"Post 75th Percentile\", \"Post Maximum\"]\n",
    "                        \n",
    "                        df_statistics = pd.merge(df_pre_statistics_all_vehicles, df_post_statistics_all_vehicles, how='inner', \n",
    "                                                left_on=[\"Pre RPM Bin\", \"Pre Speed Bin\"],\n",
    "                                                right_on = [\"Post RPM Bin\", \"Post Speed Bin\"])\n",
    "                        \n",
    "                        df_statistics = df_statistics.drop_duplicates()\n",
    "\n",
    "                        indices_remove = df_statistics[(df_statistics['Pre Count']<5)].index\n",
    "                        df_statistics.drop(indices_remove, inplace=True)\n",
    "                        \n",
    "                        \n",
    "                        #df_statistics.loc[(df_statistics['Pre Count']<5), ['Pre Mean', 'Post Mean']] = 0 \n",
    "\n",
    "                        df_statistics[\"Status\"] = \"Good\"\n",
    "                        df_statistics.loc[(df_statistics[\"Post Mean\"]>df_statistics[\"Pre Mean\"]), \"Status\"] = \"Bad\"\n",
    "                        \n",
    "                        c = df_statistics[(df_statistics[\"Post Mean\"]<df_statistics[\"Pre Mean\"])].shape[0]\n",
    "\n",
    "                        fraction_good_bins = df_statistics[(df_statistics[\"Post Mean\"]<df_statistics[\"Pre Mean\"])].shape[0]/df_statistics.shape[0]\n",
    "\n",
    "                        \n",
    "                        print(\"fraction of good bins: \", fraction_good_bins)\n",
    "                        # for \"high\" soot burn\n",
    "                        # the logic goes something like this\n",
    "                        # if 0/4 bins has the post-dp < pre-dp, classify as low\n",
    "                        # if 1/4 or 2/4 has the post-dp < pre-dp, classify as medium \n",
    "                        if burn_quality == 'high' and fraction_good_bins == 0:\n",
    "                                burn_quality = 'low'\n",
    "                                burn_quality_percentage = burn_quality_percentage/3\n",
    "                        elif burn_quality == 'high' and fraction_good_bins <= 0.5 and fraction_good_bins != 0:\n",
    "                                burn_quality = 'medium'\n",
    "                                burn_quality_percentage = burn_quality_percentage/2   \n",
    "\n",
    "                         # for \"low\" soot burn\n",
    "                        # the logic goes something like this\n",
    "                        # if 3/4 or 4/4 has the post-dp < pre-dp, classify as medium \n",
    "                        if burn_quality == 'low' and fraction_good_bins > 0.5:\n",
    "                                burn_quality = 'medium'\n",
    "                                burn_quality_percentage = burn_quality_percentage * 2\n",
    "                                  \n",
    "                        if burn_quality == 'low':\n",
    "                                print(df_statistics)\n",
    "                                if df_statistics.loc[(df_statistics[\"Pre Speed Bin\"] == str(\">\")+str(SPEED_THRESHOLD)),\"Pre Count\"].sum() == 0:\n",
    "                                                evidence = \"Speed conditions were insufficiently met\"\n",
    "                                else:\n",
    "                                        status_ls = df_statistics.loc[(df_statistics[\"Pre Speed Bin\"] == str(\">\")+str(SPEED_THRESHOLD)),\"Status\"].tolist()\n",
    "                                        any_bad = any(element == \"bad\" for element in status_ls)\n",
    "                                        if any_bad:\n",
    "                                                evidence = \"Speed conditions were insufficiently met\"\n",
    "                                        else:\n",
    "                                                evidence =  \"Higher soot load despite speed conditions were met\"\n",
    "                        if burn_quality == 'high':  \n",
    "                                evidence = \"Duration and speed conditions were met\"\n",
    "                elif burn_quality == 'medium' :\n",
    "                        evidence = \"Duration and Speed conditions were moderately met\"\n",
    "\n",
    "        return evidence, burn_quality                        \n",
    "\n",
    "\n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_PID_data(X_Value,Number_of_features):\n",
    "\n",
    "    # DPFDP has minimum length DATA[1,:], so resample all other variables  w.r.t. DPFDP\n",
    "    Samples = len(X_Value[1])\n",
    "    #print(len(X_Value[0]))\n",
    "    DATA = np.zeros((Number_of_features,Samples))\n",
    "    TEMP = np.transpose(np.array(X_Value[1]))\n",
    " \n",
    "    for cnt in range(0,Number_of_features):\n",
    "        if (len(X_Value[cnt]) > 0):\n",
    "            DATA[cnt,:] = np.transpose(np.array(signal.resample(X_Value[cnt], Samples)))\n",
    "\n",
    "    DATA[1,:] = TEMP\n",
    "\n",
    "    return DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_PID_data_v3(data, PROTOCOL,LABEL):\n",
    "    \n",
    "    if (PROTOCOL == 'SAE'):\n",
    "\n",
    "        if LABEL == 'IMAP':\n",
    "            PID_TAG = '106'\n",
    "        elif LABEL == 'ENGINE LOAD':\n",
    "            PID_TAG = '92'\n",
    "        elif LABEL == 'ENGINE RPM':\n",
    "            PID_TAG = '190'\n",
    "        elif LABEL == 'FUEL RATE':\n",
    "            PID_TAG = '183'\n",
    "        elif LABEL == 'MAF':\n",
    "            PID_TAG = '132'\n",
    "        elif LABEL == 'BOOST':\n",
    "            PID_TAG = '102'\n",
    "        elif LABEL == 'BAROMETER':\n",
    "            PID_TAG = '108'\n",
    "        elif LABEL == 'THROTTLE':\n",
    "            PID_TAG = '91'\n",
    "        elif LABEL == 'ATGMF': # Eaxuast Gas Flow Rate\n",
    "            PID_TAG = '3236'\n",
    "        elif LABEL == 'DPFDP': # DPF Diffrential Pressure (across DPF)\n",
    "            PID_TAG = '3251'\n",
    "        elif LABEL == 'SCRT':   # SCR Catalyst Temperature Before Catalyst (DPF out)\n",
    "            PID_TAG = '4360'\n",
    "        elif LABEL == 'SPEED': # Wheep based Vehicle Speed\n",
    "            PID_TAG = '84'\n",
    "        elif LABEL == 'DPFINT':# DPF in Temperature Before DPF (DOC out)\n",
    "            PID_TAG = '4766' #4766\n",
    "        elif LABEL == 'IS': #  regen inhibited\n",
    "            PID_TAG = '3703'        \n",
    "        elif LABEL == 'FUEL USE': #  Total fuel used (high precision)\n",
    "            PID_TAG = '5054'        \n",
    "        elif LABEL == 'DISTANCE': #  Total distance travelled (high precision)\n",
    "            PID_TAG = '917' # 245\n",
    "        elif LABEL == 'SOOTLOAD':\n",
    "            PID_TAG = '5466' # 245 #3719 generic check       \n",
    "        elif LABEL == 'ACTIVEREGEN':\n",
    "            PID_TAG = '3700' # 245\n",
    "\n",
    "    elif (PROTOCOL == 'SAE_AVG'):\n",
    "\n",
    "        if LABEL == 'IMAP':\n",
    "            PID_TAG = 'spn_106_avg'\n",
    "        elif LABEL == 'ENGINE LOAD':\n",
    "            PID_TAG = 'spn_92_avg'\n",
    "        elif LABEL == 'ENGINE RPM':\n",
    "            PID_TAG = 'spn_190_avg'\n",
    "        elif LABEL == 'FUEL RATE':\n",
    "            PID_TAG = 'spn_183_avg'\n",
    "        elif LABEL == 'MAF':\n",
    "            PID_TAG = 'spn_132_avg'\n",
    "        elif LABEL == 'BOOST':\n",
    "            PID_TAG = 'spn_102_avg'\n",
    "        elif LABEL == 'BAROMETER':\n",
    "            PID_TAG = 'spn_108_avg'\n",
    "        elif LABEL == 'THROTTLE':\n",
    "            PID_TAG = 'spn_91_avg'\n",
    "        elif LABEL == 'ATGMF': # Eaxuast Gas Flow Rate\n",
    "            PID_TAG = 'spn_3236_avg'\n",
    "        elif LABEL == 'DPFDP': # DPF Diffrential Pressure (across DPF)\n",
    "            PID_TAG = 'spn_3251_avg'\n",
    "        elif LABEL == 'SCRT':   # SCR Catalyst Temperature Before Catalyst (DPF out)\n",
    "            PID_TAG = 'spn_4360_avg'\n",
    "        elif LABEL == 'SPEED': # Wheep based Vehicle Speed\n",
    "            PID_TAG = 'spn_84_avg'\n",
    "        elif LABEL == 'DPFINT':# DPF in Temperature Before DPF (DOC out)\n",
    "            PID_TAG = 'spn_4766_avg' #4766\n",
    "        elif LABEL == 'IS': #  regen inhibited\n",
    "            PID_TAG = 'spn_3703_avg'        \n",
    "        elif LABEL == 'FUEL USE': #  Total fuel used (high precision)\n",
    "            PID_TAG = 'spn_5054_avg'        \n",
    "        elif LABEL == 'DISTANCE': #  Total distance travelled (high precision)\n",
    "            PID_TAG = 'spn_917_avg' # 245\n",
    "        elif LABEL == 'SOOTLOAD':\n",
    "            PID_TAG = 'spn_5466_avg' # 245 #3719 generic check       \n",
    "        elif LABEL == 'ACTIVEREGEN':\n",
    "            PID_TAG = 'spn_3700_avg' # 245\n",
    "        \n",
    "\n",
    "    elif(PROTOCOL == 'ISO'):\n",
    "\n",
    "        if LABEL == 'IMAP':\n",
    "            PID_TAG = '87BC'#MODIFY the \"if PID_TAG in State1:\" loop (append for loop on top)  \n",
    "        elif LABEL == 'ENGINE LOAD':\n",
    "            PID_TAG = '04'\n",
    "        elif LABEL == 'ENGINE RPM':\n",
    "            PID_TAG = '0C'\n",
    "        elif LABEL == 'FUEL RATE':\n",
    "            PID_TAG = '5E'\n",
    "        elif LABEL == 'MAF':\n",
    "            PID_TAG = '10'\n",
    "        elif LABEL == 'BOOST':\n",
    "            PID_TAG = '102'\n",
    "        elif LABEL == 'BAROMETER':\n",
    "            PID_TAG = '33'\n",
    "        elif LABEL == 'THROTTLE':\n",
    "            PID_TAG = '49'#MODIFY the \"if PID_TAG in State1:\" loop (append for loop on top)\n",
    "        elif LABEL == 'DPFDP': # DPF Diffrential Pressure (across DPF)\n",
    "            PID_TAG = '7A'\n",
    "    Time_vec = []\n",
    "    Val_vec = []\n",
    "\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        if \"pids\" in data[i]:\n",
    "            if len(data[i]['pids'])>0:\n",
    "                for sub_pid_cnt in range(0,len(data[i]['pids'])):\n",
    "                    State = data[i]['pids'][sub_pid_cnt]\n",
    "                    if PID_TAG in State:\n",
    "                        Time_vec.append(State[PID_TAG]['timestamp'])\n",
    "                        Val_vec.append(State[PID_TAG]['value'][0])\n",
    "      \n",
    "                \n",
    "    return Time_vec,Val_vec        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"D:/products/time_series/DPF_2.0_TESTING_DATA/1231762781519216640_DP_included/\"\n",
    "VARIABLES = ['ENGINE RPM', 'DPFDP', 'SPEED']\n",
    "\n",
    "# dir_list = os.listdir(PATH)\n",
    "# print(dir_list)\n",
    "# DATA = np.array([], dtype=np.int64).reshape(len(VARIABLES),0)\n",
    "#for data_packet_cnt in range(0,len(dir_list)):\n",
    "#OBD_data_path = PATH + dir_list[data_packet_cnt]\n",
    "path = \"D:/products/time_series/DPF_2.0_TESTING_DATA/1231762781519216640/\" \n",
    "#OBD_data_path = \"D:/products/time_series/DPF_2.0_TESTING_DATA/1231762781519216640_1709231400000_1714933800000/5TH_MY_REGEN/1231762781519216640_1714897426000_1714933800000.json\"\n",
    "#OBD_data = [json.loads(line) for line in open(OBD_data_path, 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle = 1231762781519216640\n",
    "AR_start_time = [1714877820000, 1714704120000, 1714702800000, 1714702620000, 1714653720000, 1714268220000]  \n",
    "AR_end_time = [1714879680000,1714704900000, 1714703820000, 1714702740000, 1714654800000, 1714269600000]\n",
    "for i in range(len(AR_start_time)):\n",
    "    print(AR_start_time[i])\n",
    "    print(AR_end_time[i])\n",
    "    Start_TS = AR_start_time[i] - 1*60*60*1000\n",
    "    End_TS = AR_end_time[i] + 1*60*60*1000\n",
    "    print(\"this is the starting timestamp \", Start_TS)\n",
    "    print(\"this is the ending timestamp \", End_TS)\n",
    "    URL = ' https://old-data-downloader.intangles-aws-us-east-1.intangles.us/download/' + str(vehicle) +  \"/\" + str(Start_TS) + \"/\" + str(End_TS)\n",
    "    r = requests.get(URL,stream=True)\n",
    "    OBD_data = r.json() \n",
    "    print(OBD_data[0])\n",
    "    dp_inst_Time, dp_inst_Value = extract_PID_data_v3(OBD_data, 'SAE_AVG', 'DPFDP')\n",
    "    rpm_inst_Time, rpm_inst_Value = extract_PID_data_v3(OBD_data, 'SAE_AVG', 'ENGINE RPM')\n",
    "    throttle_inst_Time, throttle_inst_Value = extract_PID_data_v3(OBD_data, 'SAE_AVG', 'THROTTLE')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_inst_Time[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_rpm_constrained = []\n",
    "throttle_rpm_constrained = []\n",
    "time_rpm_constrained = []\n",
    "rpm_constrained = []\n",
    "for i in range(len(dp_inst_Time)):\n",
    "    if rpm_inst_Value[i]>=1000 and rpm_inst_Value[i]<=2000:\n",
    "        dp_rpm_constrained.append(dp_inst_Value[i])\n",
    "        time_rpm_constrained.append(dp_inst_Time[i])\n",
    "        rpm_constrained.append(rpm_inst_Value[i])\n",
    "        throttle_rpm_constrained.append(throttle_inst_Value[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(throttle_rpm_constrained)\n",
    "higher_throttle = []\n",
    "for i in range(len(throttle_rpm_constrained)):\n",
    "    if throttle_rpm_constrained[i]>=30:\n",
    "        higher_throttle.append(throttle_rpm_constrained[i])\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(higher_throttle)/len(throttle_rpm_constrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_rpm_throttle_constrained = []\n",
    "time_rpm_throttle_constrained = []\n",
    "rpm_throttle_constrained = []\n",
    "for i in range(len(dp_rpm_constrained)):\n",
    "    if throttle_inst_Value[i]>=50:\n",
    "        dp_rpm_throttle_constrained.append(dp_inst_Value[i])\n",
    "        time_rpm_throttle_constrained.append(dp_inst_Time[i])\n",
    "        rpm_throttle_constrained.append(rpm_inst_Value[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, start_idx = find_nearest(time_rpm_throttle_constrained, AR_start_time[0])\n",
    "_, end_idx = find_nearest(time_rpm_throttle_constrained, AR_end_time[0])\n",
    "_, last_idx = find_nearest(time_rpm_throttle_constrained, AR_end_time[0] + 60*60*1000)\n",
    "mid_idx = (end_idx + start_idx)//2\n",
    "print(mid_idx - start_idx + 1)\n",
    "print(last_idx-end_idx+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rpm_throttle_constrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rpm_constrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_rpm = rpm_throttle_constrained[:mid_idx]\n",
    "post_rpm = rpm_throttle_constrained[end_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dp_rpm_throttle_constrained.append(dp_inst_Value[i])\n",
    "# time_rpm_throttle_constrained.append(dp_inst_Time[i])\n",
    "# rpm_throttle_constrained.append(rpm_inst_Value[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_low_rpm = []\n",
    "post_low_rpm = []\n",
    "pre_high_rpm = []\n",
    "post_high_rpm = []\n",
    "for i in range(len(pre_rpm)):\n",
    "    if pre_rpm[i]>=1000 and pre_rpm[i]<1400:\n",
    "        pre_low_rpm.append(pre_rpm[i])\n",
    "    elif pre_rpm[i]>=1400 and pre_rpm[i]<=2000:\n",
    "        pre_high_rpm.append(pre_rpm[i])\n",
    "for i in range(len(post_rpm)):\n",
    "    if post_rpm[i]>=1000 and post_rpm[i]<1400:\n",
    "        post_low_rpm.append(post_rpm[i])\n",
    "    elif post_rpm[i]>=1400 and post_rpm[i]<=2000:\n",
    "        post_high_rpm.append(post_rpm[i])        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pre_low_rpm))\n",
    "print(len(pre_high_rpm))\n",
    "print(len(post_low_rpm))\n",
    "print(len(post_high_rpm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking of the logic done above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time = []\n",
    "rpm_Val = []\n",
    "speed_Val = []\n",
    "dp_Val= []\n",
    "\n",
    "dir_packets = os.listdir(path)\n",
    "dir_packets.sort()\n",
    "for packet in dir_packets:\n",
    "    dir_path = path + str(packet)\n",
    "    OBD_data = [json.loads(line) for line in open(dir_path, 'r')]\n",
    "    if len(OBD_data[0]['results']['data']):\n",
    "        rpm_inst_Time, rpm_inst_Value = extract_PID_data_v3(OBD_data[0]['results']['data'], 'SAE_AVG', 'ENGINE RPM')\n",
    "        dp_inst_Time, dp_inst_Value = extract_PID_data_v3(OBD_data[0]['results']['data'], 'SAE_AVG', 'DPFDP')\n",
    "        speed_inst_Time, speed_inst_Value = extract_PID_data_v3(OBD_data[0]['results']['data'], 'SAE_AVG', 'SPEED')\n",
    "        Time.extend(rpm_inst_Time)\n",
    "        rpm_Val.extend(rpm_inst_Value)\n",
    "        speed_Val.extend(speed_inst_Value)\n",
    "        dp_Val.extend(dp_inst_Value)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create some data\n",
    "x = np.arange(len(dp_Val))\n",
    "y = dp_Val\n",
    "\n",
    "# Create a Plotly figure\n",
    "fig = go.Figure(data=go.Scatter(x=x, y=y, mode='markers', marker=dict(color='blue')))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title='DP-Value vs Engine-Hours', xaxis_title='Engine-Hours', yaxis_title='DP Value')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying RPM constraint on the DP-Values\n",
    "dp_value_rpm_constrained = []\n",
    "rpm_value_constrained = []\n",
    "speed_value_rpm_constrained = []\n",
    "time_constrained = []\n",
    "for i in range(len(dp_Val)):\n",
    "    if rpm_Val[i]>=1000 and rpm_Val[i]<=2000:\n",
    "        rpm_value_constrained.append(rpm_Val[i])\n",
    "        dp_value_rpm_constrained.append(dp_Val[i])\n",
    "        speed_value_rpm_constrained.append(speed_Val[i])\n",
    "        time_constrained.append(Time[i])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create some data\n",
    "x = np.arange(len(dp_value_rpm_constrained))\n",
    "y = dp_value_rpm_constrained\n",
    "\n",
    "# Create a Plotly figure\n",
    "fig = go.Figure(data=go.Scatter(x=x, y=y, mode='markers', marker=dict(color='blue')))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title='DP-Value Constrained vs Engine-Hours', xaxis_title='Engine-Hours', yaxis_title='DP Value')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying RPN constraint to see how the data looks like after that\n",
    "# 1000 to 2000\n",
    "col=[]\n",
    "for i in range(0,len(dp_value_rpm_constrained)):\n",
    "    if 1000<=rpm_value_constrained[i] and rpm_value_constrained[i]<1500:\n",
    "        col.append('[(1000, 1500)] or [lowrpm]')   \n",
    "    elif rpm_value_constrained[i]>=1500 and rpm_value_constrained[i]<2000:\n",
    "        col.append('[(1500, 2000)] or [highrpm]')\n",
    "data = {'Engine_Hours': np.arange(len(dp_value_rpm_constrained)), 'DP_Value': dp_value_rpm_constrained}\n",
    "df = pd.DataFrame(data)\n",
    "fig =px.scatter(df, x='Engine_Hours', y='DP_Value', color=col, color_discrete_map={'[(1000, 1500)] or [lowrpm]':'blue',\n",
    "                                                                                    '[(1500, 2000)] or [highrpm]': 'orange',\n",
    "                                                                                       }) \n",
    "fig.show()                                                                                           \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying RPN constraint to see how the data looks like after that\n",
    "# 1000 to 2000 and 80 are RPM and speed thresholds respectively\n",
    "import plotly.express as px\n",
    "col=[]\n",
    "for i in range(0,len(dp_value_rpm_constrained)):\n",
    "    if (1000<=rpm_value_constrained[i] and rpm_value_constrained[i]<1500) and speed_value_rpm_constrained[i]<=80:\n",
    "        col.append('[(1000, 1500), <=80] or [lowrpm, lowspeed]')\n",
    "    elif (1000<=rpm_value_constrained[i] and rpm_value_constrained[i]<1500) and speed_value_rpm_constrained[i]>80:\n",
    "        col.append('[(1000, 1500), >80] or [lowrpm, lowspeed]')       \n",
    "    elif (rpm_value_constrained[i]>=1500 and rpm_value_constrained[i]<2000) and speed_value_rpm_constrained[i]<=80:\n",
    "        col.append('[(1500, 2000), <=80] or [highrpm, lowspeed]')\n",
    "    elif (rpm_value_constrained[i]>=1500 and rpm_value_constrained[i]<2000) and speed_value_rpm_constrained[i]>80:\n",
    "        col.append('[(1500, 2000), >80] or [highrpm, lowspeed]')    \n",
    "data = {'Engine_Hours': np.arange(len(dp_value_rpm_constrained)), 'DP_Value': dp_value_rpm_constrained}\n",
    "df = pd.DataFrame(data)\n",
    "fig =px.scatter(df, x='Engine_Hours', y='DP_Value', color=col, color_discrete_map={'[(1000, 1500), <=80] or [lowrpm, lowspeed]':'blue',\n",
    "                                                                                    '[(1000, 1500), >80] or [lowrpm, lowspeed]': 'green',\n",
    "                                                                                    '[(1500, 2000), <=80] or [highrpm, lowspeed]': 'orange',\n",
    "                                                                                    '[(1500, 2000), >80] or [highrpm, lowspeed]': 'purple'\n",
    "                                                                                       }) \n",
    "fig.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AR_start_time = [1714877820000, 1714704120000, 1714702800000, 1714702620000, 1714653720000, 1714268220000]  \n",
    "AR_end_time = [1714879680000,1714704900000, 1714703820000, 1714702740000, 1714654800000, 1714269600000]\n",
    "BURN_QUALITY = ['high', 'high', 'high', 'low', 'high', 'high']\n",
    "for i in range(len(AR_start_time)):\n",
    "       print(BURN_QUALITY[i])\n",
    "       _, start_idx = find_nearest(time_constrained, AR_start_time[i])\n",
    "       _, end_idx = find_nearest(time_constrained, AR_end_time[i])\n",
    "       mid_idx = (start_idx + end_idx)//2\n",
    "       pre_dp_window = dp_value_rpm_constrained[mid_idx-50:mid_idx]\n",
    "       post_dp_window = dp_value_rpm_constrained[end_idx: end_idx+50]\n",
    "\n",
    "       pre_rpm_window = rpm_value_constrained[mid_idx-50:mid_idx]\n",
    "       post_rpm_window = rpm_value_constrained[end_idx: end_idx+50]\n",
    "\n",
    "       pre_speed_window = speed_value_rpm_constrained[mid_idx-50:mid_idx]\n",
    "       post_speed_window = speed_value_rpm_constrained[end_idx: end_idx+50]\n",
    "\n",
    "       SPEED_THRESHOLD = 80\n",
    "       RPM_RANGE = [1000, 2000]\n",
    "       burn_quality = BURN_QUALITY[i]\n",
    "       burn_quality_percentage = 0.8\n",
    "       start_timestamp = AR_start_time[i]\n",
    "       end_timestamp = AR_end_time[i]\n",
    "       \n",
    "       evidence, burn_quality = regeneration_evidence_v2(pre_dp_window, post_dp_window, \n",
    "                          pre_rpm_window, post_rpm_window,\n",
    "                          pre_speed_window, post_speed_window,\n",
    "                          SPEED_THRESHOLD, RPM_RANGE, burn_quality,\n",
    "                          burn_quality_percentage,\n",
    "                          start_timestamp, end_timestamp)\n",
    "       print(\"this is the evidence: \", evidence)                   \n",
    "       print(i)                   \n",
    "       #break                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_statistics, evidence = regeneration_evidence_v2(pre_dp_window, post_dp_window, \n",
    "                          pre_rpm_window, post_rpm_window,\n",
    "                          pre_speed_window, post_speed_window,\n",
    "                          SPEED_THRESHOLD, RPM_RANGE, burn_quality,\n",
    "                          burn_quality_percentage,\n",
    "                          start_timestamp, end_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying RPN constraint to see how the data looks like after that\n",
    "# 1000 to 2000\n",
    "col=[]\n",
    "        for i in range(0,len(X_2[1,:])):\n",
    "            if 1000<=X_2[0][i] and X_2[0][i]<1500 and X_2[5][i]>40:\n",
    "                col.append('[(1000, 1500) & >40] or [lowrpm, highspeed]')\n",
    "            elif 1000<=X_2[0][i] and X_2[0][i]<1500 and X_2[5][i]<=40:\n",
    "                col.append('[(1000, 1500) & <=40] or [lowrpm, lowspeed]')    \n",
    "            elif X_2[0][i]>=1500 and X_2[0][i]<2000 and X_2[5][i]>40:\n",
    "                col.append('[(1500, 2000) & >40] or [highrpm, highspeed]')\n",
    "            elif X_2[0][i]>=1500 and X_2[0][i]<2000 and X_2[5][i]<=40:\n",
    "                col.append('[(1500, 2000) & <=40] or [highrpm, lowspeed]')   \n",
    "                \n",
    "\n",
    "        data = {'Engine_Hours': np.arange(len(T_2)), 'DP_Value': X_2[1,:]}\n",
    "        df = pd.DataFrame(data)    \n",
    "        #utc_Time = [datetime.utcfromtimestamp(ms / 1000).strftime('%Y-%m-%d %H:%M:%S') for ms in T_2] \n",
    "\n",
    "        # fig = px.scatter(df, x='utc_Time', y='DP_Value', color=col, color_discrete_map={'(1000, 1500)': 'green', '(1500, 2000)': 'yellow'})\n",
    "        # fig.add_trace(go.Scatter(x=np.arange(len(X_4[1])), y=regeneration_binary_signal, mode='markers', name='Regeneration Signal', marker=dict(color='red')))\n",
    "        fig = px.scatter(df, x='Engine_Hours', y='DP_Value', color=col, color_discrete_map={'[(1000, 1500) & >40] or [lowrpm, highspeed]':'green',\n",
    "                                                                                        '[(1000, 1500) & <=40] or [lowrpm, lowspeed]':'blue',\n",
    "                                                                                        '[(1500, 2000) & >40] or [highrpm, highspeed]': 'orange',\n",
    "                                                                                        '[(1500, 2000) & <=40] or [highrpm, lowspeed]': 'purple'})\n",
    "       fig.update_layout(\n",
    "            title={\n",
    "                'text': str(df_vector_to_be_explored1.loc[(df_vector_to_be_explored1[\"Vehicle_ID\"]==int(vehicle)) & \n",
    "                                                                 (df_vector_to_be_explored1[\"Active Regeneration Start Time\"]==start_regeneration_time[start_idx])\n",
    "                                                                 &  (df_vector_to_be_explored1[\"Active Regeneration End Time\"]==end_regeneration_time[start_idx]),\n",
    "                                                                 'burn_quantification' ].values[0]) + \" soot\" + \" burn\"\n",
    "                                                                 ,\n",
    "                'y': 0.9,  # Adjust the vertical position\n",
    "                'x': 0.5,  # Adjust the horizontal position\n",
    "                'xanchor': 'center',\n",
    "                'yanchor': 'top',\n",
    "                'font': dict(\n",
    "                    family=\"Arial\",\n",
    "                    size=24,\n",
    "                    color=\"black\"\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5th May, 08:27 AM  to 5th May, 08:58 AM  'High'\n",
    "# 3rd May, 08:12 AM to 3rd May, 08:25 AM 'High'\n",
    "# 3rd May, 07:50 AM to 3rd May, 08:07 AM 'High'\n",
    "# 3rd May, 07:47 AM to 3rd May, 07:49 AM 'Failed'\n",
    "# 2nd May, 06:12 PM to 2nd May, 06:30 PM 'High'\n",
    "# 28th Apr, 07:07 AM to 28th Apr, 07:30 AM  'High'\n",
    "AR_start_time = [1714877820000, 1714704120000, 1714702800000, 1714702620000, 1714653720000, 1714268220000]  \n",
    "AR_end_time = [1714879680000,1714704900000, 1714703820000, 1714702740000, 1714654800000, 1714269600000]\n",
    "BURN_QUALITY = ['High', 'High', 'High', 'Failed', 'High', 'High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(AR_start_time)):\n",
    "    regeneration_start_idx = Time.index(AR_start_time[i])\n",
    "    regeneration_end_idx = Time.index(AR_end_time[i])\n",
    "    mid_idx = (regeneration_start_idx + regeneration_end_idx)//2\n",
    "    pre_dp_window = dp_Val[(mid_idx - 50):mid_idx]\n",
    "    pre_rpm_window "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBD_data[0]['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIABLES = ['ENGINE RPM', 'DPFDP', 'SPEED']\n",
    "Time_vec,Val_vec = extract_PID_data_v3(OBD_data[0]['results']['data'], 'SAE', 'DPFDP')\n",
    "rpm_Time = []\n",
    "rpm_Val = []\n",
    "\n",
    "dp_Time = []\n",
    "dp_Val = []\n",
    "\n",
    "speed_Time = []\n",
    "speed_Val = []\n",
    "for var_type in VARIABLES:\n",
    "    X_Time, X_Value = extract_PID_data_v3(OBD_data[0]['results']['data'],'SAE_AVG',var_type)\n",
    "    if var_type == 'ENGINE RPM':\n",
    "        rpm_Time.extend(X_Time)\n",
    "        rpm_Val.extend(X_Value)\n",
    "    elif var_type == 'DPFDP':\n",
    "        dp_Time.extend(X_Time)\n",
    "        dp_Val.extend(X_Value)  \n",
    "    elif var_type == 'SPEED':\n",
    "        speed_Time.extend(X_Time)\n",
    "        speed_Val.extend(X_Value)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"rpm frequency\")\n",
    "ls_rpm_frequency = []\n",
    "for i in range(1, len(rpm_Time)):\n",
    "    ls_rpm_frequency.append((rpm_Time[i]-rpm_Time[i-1])/(1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dp frequency\")\n",
    "ls_dp_frequency = []\n",
    "for i in range(1, len(dp_Time)):\n",
    "    ls_dp_frequency.append((dp_Time[i]-dp_Time[i-1])/(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"speed frequency\")\n",
    "ls_speed_frequency = []\n",
    "for i in range(1, len(dp_Time)):\n",
    "    ls_speed_frequency.append((dp_Time[i]-dp_Time[i-1])/(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_regeneration_start = 1714877820000\n",
    "active_regeneration_end = 1714879680000\n",
    "\n",
    "_, active_regeneration_start_idx =  find_nearest(dp_Time, active_regeneration_start)\n",
    "_, active_regeneration_end_idx =  find_nearest(dp_Time, active_regeneration_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_idx = (active_regeneration_start_idx + active_regeneration_end_idx)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_dp_window, post_dp_window, \n",
    "# pre_rpm_window, post_rpm_window,\n",
    "# pre_speed_window, post_speed_window,\n",
    "# SPEED_THRESHOLD, RPM_RANGE, burn_quality,\n",
    "# burn_quality_percentage,\n",
    "# start_timestamp, end_timestamp\n",
    "pre_dp_window = dp_Val[(mid_idx - 50): mid_idx]\n",
    "pre_rpm_window = rpm_Val[(mid_idx - 50): mid_idx]\n",
    "pre_speed_window = speed_Val[(mid_idx - 50): mid_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_dp_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_PID_data(X_Value,Number_of_features):\n",
    "\n",
    "    # DPFDP has minimum length DATA[1,:], so resample all other variables  w.r.t. DPFDP\n",
    "    Samples = len(X_Value[1])\n",
    "    #print(len(X_Value[0]))\n",
    "    DATA = np.zeros((Number_of_features,Samples))\n",
    "    TEMP = np.transpose(np.array(X_Value[1]))\n",
    " \n",
    "    for cnt in range(0,Number_of_features):\n",
    "        if (len(X_Value[cnt]) > 0):\n",
    "            DATA[cnt,:] = np.transpose(np.array(signal.resample(X_Value[cnt], Samples)))\n",
    "\n",
    "    DATA[1,:] = TEMP\n",
    "\n",
    "    return DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"D:/products/time_series/DPF_2.0_TESTING_DATA/1231762781519216640_1709231400000_1714933800000/5TH_MY_REGEN/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(PATH)\n",
    "print(dir_list)\n",
    "DATA = np.array([], dtype=np.int64).reshape(len(VARIABLES),0)\n",
    "for data_packet_cnt in range(0,len(dir_list)):\n",
    "#for data_packet_cnt in range(0,5):\n",
    "    OBD_data_path = PATH + dir_list[data_packet_cnt] \n",
    "    OBD_data = [json.loads(line) for line in open(OBD_data_path, 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VARIABLES = ['ENGINE RPM', 'DPFDP']\n",
    "VARIABLES = ['ENGINE RPM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = np.array([], dtype=np.int64).reshape(len(VARIABLES),0)\n",
    "T_L = []\n",
    "V_L = []\n",
    "T1 = []\n",
    "for var_type in VARIABLES:\n",
    "    X_Time, X_Value = extract_PID_data_v3(OBD_data[0]['results']['data'],'SAE',var_type)\n",
    "    T_L.append(np.array((X_Time), dtype=np.int64))\n",
    "    V_L.append(np.array((X_Value), dtype=float)) \n",
    "\n",
    "\n",
    "\n",
    "# if (len(V_L[0]) > 0):\n",
    "#     Temp_time = np.array(T_L[1]) # its DP time so no need to resample\n",
    "#     Resample_data = resample_PID_data(V_L,len(VARIABLES)) # cross check by plot\n",
    "    \n",
    "#     DATA = np.concatenate((DATA,Resample_data),axis=1)\n",
    "#     T1 = np.concatenate((T1,Temp_time),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Time[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Time[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTC time: 2021-05-19 09:28:43+00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "def convert_ms_to_utc(ms):\n",
    "    # Convert milliseconds to seconds\n",
    "    seconds = ms / 1000.0\n",
    "    # Create a datetime object from the seconds, with UTC timezone\n",
    "    utc_time = datetime.utcfromtimestamp(seconds).replace(tzinfo=timezone.utc)\n",
    "    return utc_time\n",
    "\n",
    "milliseconds = 1621416523000  # Example milliseconds\n",
    "\n",
    "utc_time = convert_ms_to_utc(milliseconds)\n",
    "print(\"UTC time:\", utc_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Milliseconds since the epoch: 1715964990000\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "def convert_utc_to_ms(utc_time):\n",
    "    # Convert UTC time to POSIX timestamp\n",
    "    posix_timestamp = utc_time.timestamp()\n",
    "    # Convert POSIX timestamp to milliseconds\n",
    "    milliseconds = int(posix_timestamp * 1000)\n",
    "    return milliseconds\n",
    "\n",
    "# Example UTC time\n",
    "utc_time = datetime.utcnow().replace(tzinfo=timezone.utc)\n",
    "utc_time = datetime.fromisoformat('2024-05-17 16:56:30+00:00')\n",
    "\n",
    "\n",
    "milliseconds = convert_utc_to_ms(utc_time)\n",
    "print(\"Milliseconds since the epoch:\", milliseconds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the DPF associated plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the required PIDs from the string LABELS\n",
    "def extract_PID_data(data, PROTOCOL,LABEL):\n",
    "    \n",
    "    if (PROTOCOL == 'SAE'):\n",
    "\n",
    "        if LABEL == 'ENGINE LOAD': # Engine Load\n",
    "            PID_TAG = 'spn_92_avg'\n",
    "        elif LABEL == 'ENGINE RPM': # Engine Speed (RPM)\n",
    "            PID_TAG = 'spn_190_avg'\n",
    "        elif LABEL == 'DPFDP': # DPF Diffrential Pressure (across DPF)\n",
    "            PID_TAG = 'spn_3251_avg'\n",
    "        elif LABEL == 'SPEED': # Wheep based Vehicle Speed\n",
    "            PID_TAG = 'spn_84_avg'\n",
    "        elif LABEL == 'DPFINT':# DPF in Temperature Before DPF (DOC out)\n",
    "            PID_TAG = 'spn_3250_avg' \n",
    "        elif LABEL == 'SOOTLOAD_3719': #  Soot load  \n",
    "            PID_TAG = 'spn_3719_avg' \n",
    "        elif LABEL == 'SOOTLOAD_5466': # Soot load (Regen threshold)    \n",
    "            PID_TAG = 'spn_5466_avg'      \n",
    "        elif LABEL == 'ACTIVEREGEN':  # Regen status\n",
    "            PID_TAG = 'spn_3700_avg' \n",
    "                  \n",
    "\n",
    "    Time_vec = []\n",
    "    Val_vec = []\n",
    "    \n",
    "    for data_cnt in range(0,len(data)):\n",
    "        if \"pids\" in data[data_cnt]:\n",
    "            if len(data[data_cnt]['pids'])>0:\n",
    "                for sub_pid_cnt in range(0,len(data[data_cnt]['pids'])):  #this loop\n",
    "                    State = data[data_cnt]['pids'][sub_pid_cnt]\n",
    "                    if PID_TAG in State:\n",
    "                        #print(\"--------------------------------------------IN----------------------------------\")\n",
    "                        Time_vec.append(np.array(State[PID_TAG]['timestamp'], dtype=np.int64))\n",
    "                        Val_vec.append(np.array(State[PID_TAG]['value'], dtype=float))\n",
    "      \n",
    "    return Time_vec,Val_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import requests\n",
    "import numpy as np\n",
    "import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_id = '1318345298031935488' #T880 Dump Truck Tier 3 (Cummins X15) 2015\n",
    "Start_TS =  1723939200000\n",
    "End_TS = 1724284799000\n",
    "OBD_data_path = 'https://old-data-downloader.intangles-aws-us-east-1.intangles.us/download/' + str(vehicle_id) +  \"/\" + str(Start_TS) + \"/\" + str(End_TS)\n",
    "r = requests.get(OBD_data_path, stream=True)\n",
    "OBD_data = r.json()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure\n",
    "fig = make_subplots(rows=7, cols=1, shared_xaxes=True)\n",
    "X_Time, X_Value = extract_PID_data(OBD_data,'SAE','DPFDP')\n",
    "DP_val = []\n",
    "TS = []\n",
    "for cnt in range(0,len(X_Time)):\n",
    "    TEMP = datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc)\n",
    "    TS.append(TEMP)\n",
    "    DP_val.append(X_Value[cnt][0])\n",
    "# Add the first trace\n",
    "fig.add_trace(go.Scatter(x=TS, y=DP_val, name='DPFDP', mode='markers' ), row=1, col=1 )\n",
    "fig.add_trace(go.Scatter(x=TS, y=[7]*len(TS), name='DPFDP Threshold', mode='lines', line=dict(color='red', dash='dash')), row=1, col=1 )\n",
    "X_Time, X_Value = extract_PID_data(OBD_data,'SAE','DPFINT')\n",
    "Temp_val = []\n",
    "TS = []\n",
    "for cnt in range(0,len(X_Time)):\n",
    "    TEMP = datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc)\n",
    "    TS.append(TEMP)\n",
    "    Temp_val.append(X_Value[cnt][0])\n",
    "# Add the second trace\n",
    "fig.add_trace(go.Scatter(x=TS, y=Temp_val, name='DPFINT', mode='markers'), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(x=TS, y=[500]*len(TS), name='DPFINT Threshold', mode='lines', line=dict(color='red', dash='dash')), row=2, col=1 )\n",
    "X_Time, X_Value = extract_PID_data(OBD_data,'SAE','ENGINE RPM')\n",
    "Speed_val = []\n",
    "TS = []\n",
    "for cnt in range(0,len(X_Time)):\n",
    "    TEMP = datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc)\n",
    "    TS.append(TEMP)\n",
    "    Speed_val.append(X_Value[cnt][0])\n",
    "# Add the second trace\n",
    "fig.add_trace(go.Scatter(x=TS, y=Speed_val, name='ENGINE RPM', mode='markers'), row=3, col=1)\n",
    "X_Time, X_Value = extract_PID_data(OBD_data,'SAE','SPEED')\n",
    "Speed_val = []\n",
    "TS = []\n",
    "for cnt in range(0,len(X_Time)):\n",
    "    TEMP = datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc)\n",
    "    TS.append(TEMP)\n",
    "    Speed_val.append(X_Value[cnt][0])\n",
    "# Add the second trace\n",
    "fig.add_trace(go.Scatter(x=TS, y=Speed_val, name='SPEED', mode='markers'), row=4, col=1)\n",
    "X_Time, X_Value = extract_PID_data(OBD_data,'SAE','SOOTLOAD_5466')\n",
    "AR_val = []\n",
    "TS = []\n",
    "for cnt in range(0,len(X_Time)):\n",
    "    TEMP = datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc)\n",
    "    TS.append(TEMP)\n",
    "    AR_val.append(X_Value[cnt][0])\n",
    "# Add the second trace\n",
    "fig.add_trace(go.Scatter(x=TS, y=AR_val, name='SOOTLOAD_5466', mode='markers'), row=5, col=1)\n",
    "X_Time, X_Value = extract_PID_data(OBD_data,'SAE','SOOTLOAD_3719')\n",
    "AR_val = []\n",
    "TS = []\n",
    "for cnt in range(0,len(X_Time)):\n",
    "    TEMP = datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc)\n",
    "    TS.append(TEMP)\n",
    "    AR_val.append(X_Value[cnt][0])\n",
    "# Add the second trace\n",
    "fig.add_trace(go.Scatter(x=TS, y=AR_val, name='SOOTLOAD_3719', mode='markers'), row=6, col=1)\n",
    "X_Time, X_Value = extract_PID_data(OBD_data,'SAE','ACTIVEREGEN')\n",
    "AR_val = []\n",
    "TS = []\n",
    "for cnt in range(0,len(X_Time)):\n",
    "    TEMP = datetime.datetime.fromtimestamp((X_Time[cnt] + 19800*1000) / 1000.0, tz=datetime.timezone.utc)\n",
    "    TS.append(TEMP)\n",
    "    AR_val.append(X_Value[cnt][0])\n",
    "# Add the second trace\n",
    "fig.add_trace(go.Scatter(x=TS, y=AR_val, name='ACTIVEREGEN', mode='markers'), row=7, col=1)\n",
    "# Set the y-axis titles\n",
    "fig.update_layout(title=f\"Vehicle ID: {vehicle_id}\")\n",
    "\n",
    "#fig.show()\n",
    "\n",
    "fig.write_html(\"D:/DPF-2.0/\" + str(vehicle_id) + \"_\" + str(Start_TS) + \"_\" + str(End_TS) + \".html\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
